{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict, Counter\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodac produkcje zwracaja nowe pod grafy <check> \n",
    "# dodac do node'ow typu I id parenta, pierwszy node Typu I bedzie zawierac parenta -1 <check>\n",
    "# layer ma byc lista <check>\n",
    "# wizualizacja warstwy (brutem) <check>\n",
    "# dodac check czy mozna wywolac <check>\n",
    "#czyscic kernel i out przed pushem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Id_creator:\n",
    "    def __init__(self):\n",
    "        self.last_id = -1\n",
    "    def get_id(self):\n",
    "        self.last_id +=1\n",
    "        return self.last_id\n",
    "    def __call__(self):\n",
    "        return self.get_id()\n",
    "    \n",
    "    \n",
    "class CannotExecuteProduction(Exception):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class Graph_layers:\n",
    "    def __init__(self):\n",
    "        self._node_id_gen =  Id_creator()\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from([(self._node_id_gen(), {'pos': (0,0),'type': 'e'})])\n",
    "        self._layers=[[G]]\n",
    "        \n",
    "    def get_layer(self, i):\n",
    "        return self._layers[i]\n",
    "    \n",
    "    def add_to_layer(self,i,G):\n",
    "        return self._layers[i].append(G)\n",
    "    \n",
    "    def add_to_last_layer(self,G):\n",
    "        return self._layers[-1].append(G)\n",
    "        \n",
    "    def add_new_layer(self, G_new):\n",
    "        self._layers.append([G_new])            \n",
    "        \n",
    "    def get_last_layer_index(self):\n",
    "        return len(self._layers) - 1\n",
    "    \n",
    "    def get_last_layer(self,i):\n",
    "        return self._layers[i]\n",
    "    \n",
    "    def display_i_layer(self, i):\n",
    "        G_layer = self._layers[i]\n",
    "        G = self._layers[i][0] if  len(self._layers[i])==1 else reduce(nx.algorithms.operators.binary.compose,G_layer)\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "        nx.draw_networkx(G, pos)\n",
    "        \n",
    "    def display_layer(self, layer):\n",
    "        G_layer = layer\n",
    "        G = layer[0] if  len(layer)==1 else reduce(nx.algorithms.operators.binary.compose,G_layer)\n",
    "        \n",
    "        pos = nx.get_node_attributes(G, 'pos')\n",
    "        nx.draw_networkx(G, pos)\n",
    "        \n",
    "    def get_node_id_gen(self):\n",
    "        return self._node_id_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_i_nodes(G):\n",
    "    return [key for (key, value) in nx.get_node_attributes(G, 'type').items() if value == 'I']\n",
    "\n",
    "def get_graph_e_nodes(G):\n",
    "    return [key for (key, value) in nx.get_node_attributes(G, 'type').items() if value == 'e']\n",
    "\n",
    "def get_graph_i_nodes_by_ids(G, ids):\n",
    "    return [key for (key, value) in nx.get_node_attributes(G, 'type').items() if value == 'I' and key in ids]\n",
    "\n",
    "def get_parent_of_nodes(G, nodes):\n",
    "    return list(set([value for (key, value) in nx.get_node_attributes(G, 'parent').items() if key in nodes]))\n",
    "\n",
    "def get_distance(fst, snd):\n",
    "    return math.sqrt((fst[0]-snd[0])**2 + (fst[1]-snd[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node_grouping(defaultdict):\n",
    "    def __init__(self):\n",
    "        super(node_grouping, self).__init__(list)\n",
    "\n",
    "    def select(self, *keys):\n",
    "        return tuple(self[key] for key in keys)\n",
    "\n",
    "def group_nodes_by_attr(graph, n_ids, attr, transform=None):\n",
    "    grouping = node_grouping()\n",
    "    for n_id in n_ids:\n",
    "        node = graph.nodes[n_id]\n",
    "        if attr not in node:\n",
    "            continue\n",
    "        key = node[attr]\n",
    "        if transform:\n",
    "            key = transform(key)\n",
    "        grouping[key].append(n_id)\n",
    "    return grouping\n",
    "\n",
    "def find_common_e_neighbors(graph, id1, *ids):\n",
    "    intersection = { n_id for n_id in graph.neighbors(id1) if graph.nodes[n_id]['type'].lower() == 'e' }\n",
    "    for xid in ids:\n",
    "        intersection.intersection_update({ n_id for n_id in graph.neighbors(xid) if graph.nodes[n_id]['type'].lower() == 'e' })\n",
    "    return intersection\n",
    "\n",
    "def find_common_group_e_neighbors(graph, group1, *groups):\n",
    "    intersection = { neighbor for n_id in group1 for neighbor in graph.neighbors(n_id) if graph.nodes[neighbor]['type'].lower() == 'e' }\n",
    "    for group in groups:\n",
    "        intersection.intersection_update({ neighbor for n_id in group for neighbor in graph.neighbors(n_id) if graph.nodes[neighbor]['type'].lower() == 'e' })\n",
    "        intersection.difference_update(set(group))\n",
    "    return intersection - set(group1)\n",
    "\n",
    "def isapprox(a, b):\n",
    "    eps = 1e-10\n",
    "    ax, ay = a\n",
    "    bx, by = b\n",
    "    return abs(ax - bx) <= eps and abs(ay - by) <= eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1(G, base_node_id, n_id_gen, side_len=2, max_random_offset = 0):\n",
    "    assert(G.nodes[base_node_id]['type'].lower() == 'e' )\n",
    "    assert(len(G.nodes)==1)\n",
    "    all_new_nodes = []\n",
    "    all_new_edges = []\n",
    "    base_pos = G.nodes[base_node_id]['pos']\n",
    "    x_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "    y_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "    i_node_x, i_node_y = base_pos[0], base_pos[1]\n",
    "    i_node = (n_id_gen(), {'pos': (i_node_x+x_offset, i_node_y-y_offset), 'type': 'I','parent': base_node_id})\n",
    "    all_new_nodes.append(i_node)\n",
    "    \n",
    "    half_side_len = side_len/2\n",
    "    e_nodes = [\n",
    "        (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "        (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "        (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "        (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y - half_side_len),'type': 'e'})\n",
    "    ]\n",
    "    for i in range(len(e_nodes)):\n",
    "        all_new_edges.extend([(e_nodes[i][0],e_nodes[i+1 if i + 1 < len(e_nodes) else 0][0])])\n",
    "        all_new_edges.extend([(i_node[0],e_nodes[i][0])])\n",
    "    \n",
    "    all_new_nodes.extend(e_nodes)\n",
    "    nG = nx.Graph()\n",
    "    nG.add_nodes_from(all_new_nodes)\n",
    "    nG.add_edges_from(all_new_edges)\n",
    "    return nG, i_node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conc_duplicates(G):\n",
    "    org_nodes = list(G.nodes(data=True))\n",
    "\n",
    "    org_nodes_dict = {}\n",
    "    for node_id,data in org_nodes:\n",
    "        try:\n",
    "            org_nodes_dict[data['pos']].append(node_id)\n",
    "        except KeyError:\n",
    "            org_nodes_dict[data['pos']]=[node_id]\n",
    "\n",
    "    nodes_to_replace = {} #keys nodes to be deleted, values nodes to replace them\n",
    "    for key,ids in org_nodes_dict.items():\n",
    "        if len(ids) > 1:\n",
    "            for id_ in ids[1:]:\n",
    "                nodes_to_replace[id_] = ids[0]\n",
    "                \n",
    "    for old_node, new_node in nodes_to_replace.items():\n",
    "        neighbors = list(G.neighbors(old_node))\n",
    "        for n in neighbors:\n",
    "            G.remove_edge(old_node,n)\n",
    "            G.add_edge(new_node,n)\n",
    "        G.remove_node(old_node)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pos(pos1, pos2):\n",
    "    return ((pos1[0] + pos2[0])/2, (pos1[1] + pos2[1])/2)\n",
    "\n",
    "def rm_edge_if_exists(G,n1id,n2id):\n",
    "    try:\n",
    "        G.remove_edge(n1id,n2id)\n",
    "    except nx.NetworkXError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "#     e0 - - - e1\n",
    "#      | \\    / |\n",
    "#      |  I0    |\n",
    "#      | /   \\  |\n",
    "#     e2 - - - e3\n",
    "#\n",
    "#          |\n",
    "#         \\/\n",
    "#\n",
    "#     e0 - - - n0 - - - e1\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I1    |  I2    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    n1 - - - n2 - - - n3\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I3    |  I4    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e2 - - - n4 - - - e3\n",
    "\n",
    "def p2(G, base_node_id, n_id_gen):\n",
    "    assert(G.nodes[base_node_id]['type'].lower() == 'i')\n",
    "    nG = nx.Graph()\n",
    "    es = list(G.neighbors(base_node_id))\n",
    "    if len(es) != 4:\n",
    "        raise CannotExecuteProduction\n",
    "    e0, e1, e2, e3 = None, None, None, None\n",
    "    baseX, baseY = G.nodes[base_node_id]['pos']\n",
    "    for ex in es:\n",
    "        x,y = G.nodes[ex]['pos']\n",
    "        if x<baseX:\n",
    "            if y<baseY:\n",
    "                e2= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e0= (ex,G.nodes[ex])\n",
    "        else:\n",
    "            if y<baseY:\n",
    "                e3= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e1= (ex,G.nodes[ex])\n",
    "    if not(G.has_edge(e0[0],e1[0]) and\\\n",
    "            G.has_edge(e1[0],e3[0]) and\\\n",
    "            G.has_edge(e3[0],e2[0]) and\\\n",
    "            G.has_edge(e0[0],e2[0]) and\\\n",
    "            G.has_edge(e0[0],base_node_id) and\\\n",
    "            G.has_edge(e1[0],base_node_id) and\\\n",
    "            G.has_edge(e2[0],base_node_id) and\\\n",
    "            G.has_edge(e3[0],base_node_id)\\\n",
    "            ):\n",
    "        raise CannotExecuteProduction\n",
    "    #prepare all new verticies accord to map above\n",
    "    e0 = (n_id_gen(),{'pos': e0[1]['pos'],'type' : e0[1]['type']})\n",
    "    e1 = (n_id_gen(),{'pos': e1[1]['pos'],'type' : e1[1]['type']})\n",
    "    e2 = (n_id_gen(),{'pos': e2[1]['pos'],'type' : e2[1]['type']})\n",
    "    e3 = (n_id_gen(),{'pos': e3[1]['pos'],'type' : e3[1]['type']})\n",
    "\n",
    "    n0 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],e1[1]['pos']),'type':'e'})\n",
    "    n1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    n2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    n3 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    n4 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    \n",
    "    I1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I3 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I4 = (n_id_gen(),{'pos' : avg_pos(e3[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    # add all new edges\n",
    "    new_edges = [\n",
    "        (e0[0],n0[0]),(n0[0],e1[0]),\n",
    "        (e0[0],I1[0]),(n0[0],I1[0]), (n0[0],I2[0]),(e1[0],I2[0]),\n",
    "        (e0[0],n1[0]),(n0[0],n2[0]),(e1[0],n3[0]),\n",
    "        (n1[0],I1[0]),(n2[0],I1[0]), (n2[0],I2[0]),(n3[0],I2[0]),\n",
    "        (n1[0],n2[0]),(n2[0],n3[0]),\n",
    "        (n1[0],I3[0]),(n2[0],I3[0]), (n2[0],I4[0]),(n3[0],I4[0]),\n",
    "        (n1[0],e2[0]),(n2[0],n4[0]),(n3[0],e3[0]),\n",
    "        (e2[0],I3[0]),(n4[0],I3[0]), (n4[0],I4[0]),(e3[0],I4[0]),\n",
    "        (e2[0],n4[0]),(n4[0],e3[0]),\n",
    "    ]\n",
    "    nG.add_nodes_from([e0,e1,e2,e3,n0,n1,n2,n3,n4,I1,I2,I3,I4])\n",
    "    nG.add_edges_from(new_edges)\n",
    "    return nG\n",
    "#     conc_duplicates(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_layers = Graph_layers()\n",
    "graph_layers.display_i_layer(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "#indexing from 0 \n",
    "first_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "\n",
    "#apply p1 production\n",
    "G, i_node = p1(first_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "graph_layers.add_new_layer(G)\n",
    "\n",
    "graph_layers.display_i_layer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply p2 production\n",
    "G = graph_layers.get_layer(1)[0]\n",
    "nG = p2(G, 1, graph_layers.get_node_id_gen())\n",
    "graph_layers.add_new_layer(nG)\n",
    "graph_layers._layers[2][0].nodes(data=True)\n",
    "graph_layers.display_i_layer(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply p2 production 4 times\n",
    "G = graph_layers.get_layer(2)[0]\n",
    "graph_layers.add_new_layer( p2(G, 15, graph_layers.get_node_id_gen()))\n",
    "graph_layers.add_to_last_layer(p2(G, 18, graph_layers.get_node_id_gen()))\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply p2 production\n",
    "G = graph_layers.get_layer(2)[0]\n",
    "graph_layers.add_to_last_layer(p2(G, 17, graph_layers.get_node_id_gen()))\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply p2 production\n",
    "G = graph_layers.get_layer(2)[0]\n",
    "graph_layers.add_to_last_layer(p2(G, 16, graph_layers.get_node_id_gen()))\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests for production 1\n",
    "def test_production_one(zero_layer_G, base_node):   \n",
    "    #apply p1 production\n",
    "    G, i_node = p1(zero_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "    assert(G.number_of_nodes() == 5)\n",
    "\n",
    "    I_node_num = 0\n",
    "    I_node_id = -1\n",
    "    E_nodes = []\n",
    "    for node_id, node_type in nx.get_node_attributes(G, 'type').items():\n",
    "        if node_type == 'I':\n",
    "            I_node_num += 1\n",
    "            assert(G.degree[node_id] ==  4)\n",
    "            I_node_id = node_id                  \n",
    "        else:\n",
    "            assert(G.degree[node_id] == 3)\n",
    "            assert((node_id, I_node_id) in list(G.edges(node_id)))\n",
    "            E_nodes.append(node_id)\n",
    "    \n",
    "    assert((E_nodes[0], E_nodes[2]) not in list(G.edges))\n",
    "    assert((E_nodes[1], E_nodes[3]) not in list(G.edges))\n",
    "\n",
    "    assert(I_node_num == 1)\n",
    "    \n",
    "    assert(len(nx.get_node_attributes(G, 'parent')) == 1)\n",
    "    parent_id = list(nx.get_node_attributes(G, 'parent').items())[0][1]\n",
    "    node_id_with_parent = list(nx.get_node_attributes(G, 'parent').items())[0][0]\n",
    "    assert(base_node[0] == parent_id)\n",
    "    assert(node_id_with_parent == I_node_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct left side\n",
    "base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "zero_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "test_production_one(zero_layer_G, base_node)\n",
    "\n",
    "#empty left side\n",
    "zero_layer_G  = nx.Graph()\n",
    "try:\n",
    "    test_production_one(zero_layer_G, base_node)\n",
    "except KeyError:\n",
    "    print(\"exception when empty first layer occured\")\n",
    "\n",
    "#incorrect label \n",
    "zero_layer_G  = nx.Graph()\n",
    "zero_layer_G.add_nodes_from([(graph_layers.get_node_id_gen()(), {'pos': (0,0),'type': 'I'})])\n",
    "try:\n",
    "    test_production_one(zero_layer_G, base_node)\n",
    "except KeyError:\n",
    "    print(\"exception when incorrect label occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests for production 2\n",
    "def test_production_two(first_layer_G, i_node):   \n",
    "    #apply p2 production\n",
    "    sec_layer_G = p2(first_layer_G, i_node[0], graph_layers.get_node_id_gen())\n",
    "    \n",
    "    assert(G.number_of_nodes() == 13)\n",
    "    E_nodes_from_layer_1 = [first_layer_G.nodes[node_ID]['pos'] for i_node_ID, node_ID in first_layer_G.edges(i_node[0])]\n",
    "  \n",
    "    #check if layer two contains E nodes from layer 1 \n",
    "    assert(set(E_nodes_from_layer_1).issubset(list(nx.get_node_attributes(sec_layer_G, 'pos').values())))  \n",
    "    extreme_E_nodes_from_layer_2 = []\n",
    "       \n",
    "    for node_id, attr in sec_layer_G.nodes.data():\n",
    "        if attr['pos'] in E_nodes_from_layer_1:\n",
    "            extreme_E_nodes_from_layer_2.append((node_id, attr['pos']))\n",
    "            \n",
    "    (x_1, y_1) = extreme_E_nodes_from_layer_2[0][1]\n",
    "    (x_2, y_2) = extreme_E_nodes_from_layer_2[1][1]\n",
    "    (x_3, y_3) = extreme_E_nodes_from_layer_2[2][1]\n",
    "    (x_4, y_4) = extreme_E_nodes_from_layer_2[3][1]\n",
    "\n",
    "    I_nodes_from_layer_2 = []\n",
    "    for node_id, attr in sec_layer_G.nodes.data():\n",
    "        if attr['type'] == 'I':\n",
    "            I_nodes_from_layer_2.append((node_id, attr['pos']))\n",
    "            assert(attr['parent'] == i_node[0])\n",
    "            assert(sec_layer_G.degree[node_id] == 4)            \n",
    "    \n",
    "    subnet_neighbours = ((1, 2), (0, 3), (0, 3), (2, 1))\n",
    "    subnets = []\n",
    "    for i, (node_id, pos) in enumerate(I_nodes_from_layer_2):\n",
    "        subnet = [node_id for I_node_id, node_id in list(sec_layer_G.edges(node_id))]\n",
    "        pos = {sec_layer_G.nodes[node_id]['pos']: node_id for node_id in subnet}\n",
    "        subnets.append(set(pos.items()))\n",
    "        assert(extreme_E_nodes_from_layer_2[i][0] in subnet)\n",
    "\n",
    "        extreme_node_id = extreme_E_nodes_from_layer_2[i][0] \n",
    "        assert(sec_layer_G.degree[extreme_node_id] == 3)\n",
    "               \n",
    "        (x0, y0) = extreme_E_nodes_from_layer_2[i][1]\n",
    "        (x1, y1) = extreme_E_nodes_from_layer_2[subnet_neighbours[i][0]][1]\n",
    "        (x2, y2) = extreme_E_nodes_from_layer_2[subnet_neighbours[i][1]][1]\n",
    "\n",
    "        pos1 = ((x0+x1)/2,(y0+y1)/2)\n",
    "        assert(len(list(filter(lambda x: math.isclose(x[0],pos1[0]) and math.isclose(x[1],pos1[1]), list(pos.keys())))) == 1)\n",
    "        node_id = pos[pos1]\n",
    "        assert(sec_layer_G.degree[node_id] == 5)\n",
    "\n",
    "        pos2 = ((x0+x2)/2,(y0+y2)/2)\n",
    "        assert(len(list(filter(lambda x: math.isclose(x[0],pos2[0]) and math.isclose(x[1],pos2[1]), list(pos.keys())))) == 1)\n",
    "        node_id = pos[pos2]\n",
    "        assert(sec_layer_G.degree[node_id] == 5)\n",
    "        \n",
    "        for node in subnet:\n",
    "            nghbs = [b_node for (node_id, b_node) in list(sec_layer_G.edges(node))]\n",
    "            assert(len(set(nghbs).intersection(subnet)) == 2)\n",
    "        assert((subnet[0], subnet[3]) not in list(sec_layer_G.edges))\n",
    "        assert((subnet[1], subnet[2]) not in list(sec_layer_G.edges))\n",
    "\n",
    "        \n",
    "    #check if central element is valid\n",
    "    central_elem = subnets[0].intersection(subnets[1], subnets[2], subnets[3])\n",
    "    assert(len(central_elem) == 1)\n",
    "    entral_elem_pos = list(central_elem)[0][0]\n",
    "    assert(entral_elem_pos == ((x_1+x_4)/2, (y_1+y_4)/2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct\n",
    "base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "first_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "first_layer_G, i_node = p1(first_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "test_production_two(first_layer_G, i_node)\n",
    "\n",
    "#without one node\n",
    "first_layer_G_cp = first_layer_G.copy()\n",
    "first_layer_G_cp.remove_node(list(first_layer_G_cp.nodes)[0])\n",
    "try:\n",
    "    test_production_two(first_layer_G_cp, i_node)\n",
    "except KeyError:\n",
    "    print(\"exception when left side without one node\")\n",
    "    \n",
    "#as part of bigger graph\n",
    "first_layer_G_cp = first_layer_G.copy()\n",
    "first_layer_G_cp.add_nodes_from([(graph_layers.get_node_id_gen()(), {'pos': (-3,3),'type': 'e'})])\n",
    "test_production_two(first_layer_G_cp, i_node)\n",
    "    \n",
    "#without edge\n",
    "first_layer_G_cp = first_layer_G.copy()\n",
    "first_layer_G_cp.remove_node(list(first_layer_G_cp.nodes)[1])\n",
    "first_layer_G_cp.add_nodes_from([(graph_layers.get_node_id_gen()(), {'pos': (-1,1),'type': 'e'})])\n",
    "try:\n",
    "    test_production_two(first_layer_G_cp, i_node)\n",
    "except CannotExecuteProduction:\n",
    "    print(\"exception when left side without some edge\")\n",
    "    \n",
    "#incorrect label\n",
    "first_layer_G_cp = first_layer_G.copy()\n",
    "nb1, nb2 = list(first_layer_G_cp.nodes)[0], list(first_layer_G_cp.nodes)[2]\n",
    "first_layer_G_cp.remove_node(list(first_layer_G_cp.nodes)[1])\n",
    "new_node_id = graph_layers.get_node_id_gen()()\n",
    "first_layer_G_cp.add_nodes_from([(new_node_id, {'pos': (-1,1),'type': 'I'})])\n",
    "first_layer_G_cp.add_edge(new_node_id, nb1)\n",
    "first_layer_G_cp.add_edge(new_node_id, nb2)\n",
    "\n",
    "try:\n",
    "    test_production_two(first_layer_G_cp, i_node)\n",
    "except CannotExecuteProduction:\n",
    "    print(\"exception when left side with incorrect label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "#      I1  - e1    e1 - I3\n",
    "#        \\\\  /        \\\\ /\n",
    "#         e2          e2\n",
    "#        / \\\\         / \\\\\n",
    "#     I2  - e3     e3 - I4\n",
    "#\n",
    "#              |\n",
    "#             \\\\/\n",
    "#\n",
    "#      I1  - e1 - I3\n",
    "#        \\\\   |   /\n",
    "#            e2\n",
    "#        /   |   \\\\\n",
    "#     I2  - e3 - I4\n",
    "def p7(parent_layer, child_layer, base_node_ids, n_id_gen):\n",
    "    #finding graph in child_layer\n",
    "    first, second = None, None\n",
    "    for graph in child_layer:\n",
    "        if any(item in graph.nodes for item in base_node_ids):\n",
    "            if second != None:\n",
    "                raise CannotExecuteProduction\n",
    "            if first is None:\n",
    "                first = graph\n",
    "            else:\n",
    "                second = graph\n",
    "\n",
    "    first_i_nodes = get_graph_i_nodes_by_ids(first, base_node_ids)\n",
    "    second_i_nodes = get_graph_i_nodes_by_ids(second, base_node_ids)\n",
    "\n",
    "    #checking each I node has a parent\n",
    "    if not all('parent' in first.node[n] for n in first_i_nodes) or not all('parent' in second.node[n] for n in second_i_nodes):\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    #finding graph in parent_layer\n",
    "    parents = get_parent_of_nodes(first, first_i_nodes) + get_parent_of_nodes(second, second_i_nodes)\n",
    "    if len(parents) != 2:\n",
    "        raise CannotExecuteProduction\n",
    "    parent_graphs = [graph for graph in parent_layer if all(parent in graph.nodes for parent in parents)]\n",
    "    if len(parent_graphs) > 1:\n",
    "        raise CannotExecuteProduction\n",
    "    parent_graph = parent_graphs[0]\n",
    "    if not any(fst for fst in parent_graph.neighbors(parents[0]) for snd in parent_graph.neighbors(parents[1]) if fst == snd):\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    #finding nodes to reduce\n",
    "    nodes_to_reduce_all = [(x_n, y_n) \n",
    "         for x in first_i_nodes \n",
    "         for y in second_i_nodes \n",
    "         for x_n in first.neighbors(x) \n",
    "         for y_n in second.neighbors(y)\n",
    "         if 0.1 > get_distance(nx.get_node_attributes(first, 'pos')[x_n], nx.get_node_attributes(second, 'pos')[y_n])]\n",
    "    nodes_to_reduce = list(set(nodes_to_reduce_all))\n",
    "    \n",
    "    if len(nodes_to_reduce_all) != 6 or len(nodes_to_reduce) != 3:\n",
    "        raise CannotExecuteProduction\n",
    "    \n",
    "    possible_edges = [True for (x, _) in nodes_to_reduce for (y, _) in nodes_to_reduce if x != y and first.has_edge(x, y)]\n",
    "    if len(possible_edges) != 4:\n",
    "        raise CannotExecuteProduction\n",
    "    possible_edges = [True for (_, x) in nodes_to_reduce for (_, y) in nodes_to_reduce if x != y and second.has_edge(x, y)]\n",
    "    if len(possible_edges) != 4:\n",
    "        raise CannotExecuteProduction\n",
    "        \n",
    "    \n",
    "    #creating new correct graph\n",
    "    reversed_nodes_to_reduce = [(value, key) for (key, value) in nodes_to_reduce]\n",
    "    mapping = dict(nodes_to_reduce + reversed_nodes_to_reduce)\n",
    "\n",
    "    new_old_graph = deepcopy(first)\n",
    "    second_old_graph = nx.relabel_nodes(second, mapping, copy=True)\n",
    "\n",
    "    nodes_to_add = [(node, values)\n",
    "                             for (node, values) in second_old_graph.nodes().items() \n",
    "                             if node not in mapping.keys()]\n",
    "\n",
    "    new_old_graph.add_nodes_from(nodes_to_add)\n",
    "    new_old_graph.add_edges_from(second_old_graph.edges)\n",
    "\n",
    "    i_nodes = get_graph_i_nodes(new_old_graph)\n",
    "\n",
    "    return i_nodes, new_old_graph, [first, second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_P7(parent_layer, child_layer, base_node_ids, n_id_gen):\n",
    "    i_nodes, new_graph, old_graphs = p7(parent_layer, child_layer, base_node_ids, n_id_gen)\n",
    "    for graph in old_graphs:\n",
    "        child_layer.remove(graph)\n",
    "    child_layer.append(new_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "apply_P7(graph_layers.get_layer(2), graph_layers.get_layer(3), [41, 43, 55, 57], graph_layers.get_node_id_gen())\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "apply_P7(graph_layers.get_layer(2), graph_layers.get_layer(3), [30, 31, 55, 54], graph_layers.get_node_id_gen())\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "apply_P7(graph_layers.get_layer(2), graph_layers.get_layer(3), [29, 31, 67, 69], graph_layers.get_node_id_gen())\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_leaf_edges(parent, id_gen, offset, tiny_offset):\n",
    "    center_x, center_y = 2, 2\n",
    "    l2 = nx.Graph()\n",
    "    l2_edges = []\n",
    "    l2_nodes = []\n",
    "    upper_i = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': parent[0]})\n",
    "    lower_i = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': parent[0]})\n",
    "    l2_nodes.extend([upper_i, lower_i])\n",
    "\n",
    "    a_upper_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y + 1.5),'type': 'e'})\n",
    "    a_mid_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y),'type': 'e'})\n",
    "    a_lower_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y - 1.5),'type': 'e'})\n",
    "    b_upper_e = (id_gen.get_id(), {'pos': (center_x + 2*offset, center_y + 1.5),'type': 'e'})\n",
    "    b_mid_e = (id_gen.get_id(), {'pos': (center_x + 2*offset, center_y),'type': 'e'})\n",
    "    b_lower_e = (id_gen.get_id(), {'pos': (center_x + 2*offset, center_y - 1.5),'type': 'e'})\n",
    "\n",
    "    l2_nodes.extend([a_upper_e, a_mid_e, a_lower_e, b_upper_e, b_mid_e, b_lower_e])\n",
    "    l2_edges.extend([(a_upper_e[0], a_mid_e[0]), \n",
    "                     (a_lower_e[0], a_mid_e[0]), \n",
    "                     (a_lower_e[0], lower_i[0]),\n",
    "                     (lower_i[0], a_mid_e[0]),\n",
    "                     (upper_i[0], a_mid_e[0]),\n",
    "                     (upper_i[0], a_upper_e[0]),\n",
    "                     (b_upper_e[0], b_mid_e[0]), \n",
    "                     (b_lower_e[0], b_mid_e[0]), \n",
    "                     (b_lower_e[0], lower_i[0]),\n",
    "                     (lower_i[0], b_mid_e[0]),\n",
    "                     (upper_i[0], b_mid_e[0]),\n",
    "                     (upper_i[0], b_upper_e[0]),\n",
    "                     (b_upper_e[0], a_upper_e[0]),\n",
    "                     (b_mid_e[0], a_mid_e[0]),\n",
    "                     (b_lower_e[0], a_lower_e[0])])\n",
    "\n",
    "    l2.add_nodes_from(l2_nodes)\n",
    "    l2.add_edges_from(l2_edges)\n",
    "    return l2, [lower_i[0], upper_i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_valid_input_net():\n",
    "    graph_layers = Graph_layers()\n",
    "    side_len=2\n",
    "    parent_node_x, parent_node_y = 1, 1\n",
    "    id_gen = graph_layers.get_node_id_gen()\n",
    "    parent_node = (id_gen.get_id(), {'pos': (parent_node_x, parent_node_y), 'type': 'E','parent': -1})\n",
    "\n",
    "    half_side_len = side_len/2\n",
    "    i_nodes = [\n",
    "        (id_gen.get_id(), {'pos': (parent_node_x + half_side_len, parent_node_y - half_side_len),'type': 'I', 'parent': parent_node[0]}),\n",
    "        (id_gen.get_id(), {'pos': (parent_node_x - half_side_len, parent_node_y - half_side_len),'type': 'I', 'parent': parent_node[0]})\n",
    "    ]\n",
    "    l1_edges = []\n",
    "    for i_node in i_nodes:\n",
    "         l1_edges.extend([(i_node[0],parent_node[0])])\n",
    "\n",
    "    l1 = nx.Graph()\n",
    "    l1.add_nodes_from([parent_node])\n",
    "    l1.add_nodes_from(i_nodes)\n",
    "    l1.add_edges_from(l1_edges)\n",
    "    graph_layers.add_new_layer(l1)\n",
    "\n",
    "    center_x, center_y, offset, tiny_offset = 2, 2, -1, -0.05\n",
    "    left_graph, output_ids = create_leaf_edges(i_nodes[0], id_gen, offset, tiny_offset)\n",
    "    graph_layers.add_new_layer(left_graph)\n",
    "    offset = -offset\n",
    "    tiny_offset = -tiny_offset\n",
    "    right_graph, right_ids = create_leaf_edges(i_nodes[1], id_gen, offset, tiny_offset)\n",
    "    graph_layers.add_to_layer(2, right_graph)\n",
    "    output_ids.extend(right_ids)\n",
    "\n",
    "    return graph_layers, output_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obraz pogladowy jasne jest ze istnieja 4 permutacje izomorficzne jesli chodzi o labelkowanie wierzcholkow\n",
    "#     e0 - - - e1\n",
    "#      | \\    / |\n",
    "#     e4   I0   |\n",
    "#      | /   \\  |\n",
    "#     e2 - - - e3\n",
    "#\n",
    "#          |\n",
    "#         \\/\n",
    "#\n",
    "#     e0' - - - n0 - - - e1'\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I1    |  I2    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e4' - - - n2 - - - n3\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I3    |  I4    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e2' - - - n4 - - - e3'\n",
    "def p3(G, base_node_id, n_id_gen):\n",
    "    if not (G.nodes[base_node_id]['type'].lower() == 'i'): raise CannotExecuteProduction\n",
    "    nG = nx.Graph()\n",
    "    es = list(G.neighbors(base_node_id))\n",
    "    nghs_counter = Counter(reduce(lambda a,b : a+b ,[list(G.neighbors(e)) for e in es],es + [base_node_id]))\n",
    "    es1 = set([x for x, count in nghs_counter.items() if count >= 2]) - {base_node_id}\n",
    "    if len(es) != 4 and len(es1) != 5:\n",
    "        raise CannotExecuteProduction\n",
    "    e0, e1, e2, e3, e4 = None, None, None, None, None\n",
    "    baseX, baseY = G.nodes[base_node_id]['pos']\n",
    "    \n",
    "    \n",
    "    # get Square corners\n",
    "    for ex in es:\n",
    "        x,y = G.nodes[ex]['pos']\n",
    "        if x<baseX:\n",
    "            if y<baseY:\n",
    "                e2= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e0= (ex,G.nodes[ex])\n",
    "        else:\n",
    "            if y<baseY:\n",
    "                e3= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e1= (ex,G.nodes[ex])\n",
    "    if not all([e0,e1,e2,e3]): raise CannotExecuteProduction\n",
    "    ids = [base_node_id, e0[0], e1[0], e2[0], e3[0]]\n",
    "\n",
    "    edge0 = G.has_edge(e0[0],e1[0])\n",
    "    edge1 = G.has_edge(e0[0],e2[0])\n",
    "    edge2 = G.has_edge(e2[0],e3[0])\n",
    "    edge3 = G.has_edge(e1[0],e3[0])\n",
    "    \n",
    "    # should be 3 edges between 4 cornesrs (1 is created with extra node)\n",
    "    if(int(edge0) + int(edge1) + int(edge2) + int(edge3) != 3):\n",
    "         raise CannotExecuteProduction\n",
    "           \n",
    "    def getNodeBetween(e1Id, e2Id):\n",
    "        allNodes = list(G.neighbors(e1Id)) + list(G.neighbors(e2Id))\n",
    "        possibleNodes = [n for n in allNodes if n in list(G.neighbors(e1Id)) and n in list(G.neighbors(e2Id))]\n",
    "        return list(set(possibleNodes))\n",
    "    \n",
    "    if(not edge0):\n",
    "        possE4 = getNodeBetween(e0[0],e1[0])\n",
    "    if(not edge1):\n",
    "        possE4 = getNodeBetween(e0[0],e2[0])\n",
    "    if(not edge2):\n",
    "        possE4 = getNodeBetween(e2[0],e3[0])\n",
    "    if(not edge3):\n",
    "        possE4 = getNodeBetween(e1[0],e3[0])\n",
    " \n",
    "    # get all 'e' nodes between two nodes that does not share edge\n",
    "    maybeE4 = [ G.nodes[e] for e in possE4 if G.nodes[e]['type'].lower() == 'e']\n",
    "    if(len(maybeE4) != 1):\n",
    "        raise CannotExecuteProduction\n",
    "    \n",
    "    # this is the extra node\n",
    "    e4 = maybeE4[0]\n",
    "\n",
    "    #check if node has proper cordinates\n",
    "    if(not edge0):\n",
    "        if(e4['pos'] != avg_pos(e0[1]['pos'], e1[1]['pos'])):\n",
    "            raise CannotExecuteProduction\n",
    "    if(not edge1):\n",
    "        if(e4['pos'] != avg_pos(e0[1]['pos'], e2[1]['pos'])):\n",
    "            raise CannotExecuteProduction\n",
    "    if(not edge2):\n",
    "        if(e4['pos'] != avg_pos(e2[1]['pos'], e3[1]['pos'])):\n",
    "            raise CannotExecuteProduction\n",
    "    if(not edge3):\n",
    "        if(e4['pos'] != avg_pos(e1[1]['pos'], e3[1]['pos'])):\n",
    "            raise CannotExecuteProduction\n",
    "                                                                                     \n",
    "    e0 = (n_id_gen(),{'pos': e0[1]['pos'],'type' : e0[1]['type']})\n",
    "    e1 = (n_id_gen(),{'pos': e1[1]['pos'],'type' : e1[1]['type']})\n",
    "    e2 = (n_id_gen(),{'pos': e2[1]['pos'],'type' : e2[1]['type']})\n",
    "    e3 = (n_id_gen(),{'pos': e3[1]['pos'],'type' : e3[1]['type']})\n",
    "\n",
    "    n0 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],e1[1]['pos']),'type':'e'})\n",
    "    n1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    n2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    n3 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    n4 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    \n",
    "    I1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I3 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I4 = (n_id_gen(),{'pos' : avg_pos(e3[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    # add all new edges\n",
    "    new_edges = [\n",
    "        (e0[0],n0[0]),(n0[0],e1[0]),\n",
    "        (e0[0],I1[0]),(n0[0],I1[0]), (n0[0],I2[0]),(e1[0],I2[0]),\n",
    "        (e0[0],n1[0]),(n0[0],n2[0]),(e1[0],n3[0]),\n",
    "        (n1[0],I1[0]),(n2[0],I1[0]), (n2[0],I2[0]),(n3[0],I2[0]),\n",
    "        (n1[0],n2[0]),(n2[0],n3[0]),\n",
    "        (n1[0],I3[0]),(n2[0],I3[0]), (n2[0],I4[0]),(n3[0],I4[0]),\n",
    "        (n1[0],e2[0]),(n2[0],n4[0]),(n3[0],e3[0]),\n",
    "        (e2[0],I3[0]),(n4[0],I3[0]), (n4[0],I4[0]),(e3[0],I4[0]),\n",
    "        (e2[0],n4[0]),(n4[0],e3[0]),\n",
    "    ]\n",
    "    nG.add_nodes_from([e0,e1,e2,e3,n0,n1,n2,n3,n4,I1,I2,I3,I4])\n",
    "    nG.add_edges_from(new_edges)\n",
    "    return nG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# obraz pogladowy jasne jest ze istnieja 4 permutacje izomorficzne jesli chodzi o labelkowanie wierzcholkow\n",
    "#     e0 - e5 - e1\n",
    "#      | \\    / |\n",
    "#     e4   I0   |\n",
    "#      | /   \\  |\n",
    "#     e2 - - - e3\n",
    "#\n",
    "#          |\n",
    "#         \\/\n",
    "#\n",
    "#     e0' - - - n0 - - - e1'\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I1    |  I2    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e4' - - - n2 - - - n3\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I3    |  I4    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e2' - - - n4 - - - e3'\n",
    "def p4(G, base_node_id, n_id_gen):\n",
    "    if not (G.nodes[base_node_id]['type'].lower() == 'i'): raise CannotExecuteProduction\n",
    "    nG = nx.Graph()\n",
    "    es = list(G.neighbors(base_node_id))\n",
    "    nghs_counter = Counter(reduce(lambda a,b : a+b ,[list(G.neighbors(e)) for e in es],es + [base_node_id]))\n",
    "    es1 = set([x for x, count in nghs_counter.items() if count >= 2]) - {base_node_id}\n",
    "    if len(es) != 4 and len(es1) != 6:\n",
    "        raise CannotExecuteProduction\n",
    "    e0, e1, e2, e3, e4, e5 = None, None, None, None, None, None\n",
    "    baseX, baseY = G.nodes[base_node_id]['pos']\n",
    "    \n",
    "    \n",
    "    # get Square corners\n",
    "    for ex in es:\n",
    "        x,y = G.nodes[ex]['pos']\n",
    "        if x<baseX:\n",
    "            if y<baseY:\n",
    "                e2= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e0= (ex,G.nodes[ex])\n",
    "        else:\n",
    "            if y<baseY:\n",
    "                e3= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e1= (ex,G.nodes[ex])\n",
    "    if not all([e0,e1,e2,e3]): raise CannotExecuteProduction\n",
    "    ids = [base_node_id, e0[0], e1[0], e2[0], e3[0]]\n",
    "\n",
    "    edge0 = G.has_edge(e0[0],e1[0])\n",
    "    edge1 = G.has_edge(e0[0],e2[0])\n",
    "    edge2 = G.has_edge(e2[0],e3[0])\n",
    "    edge3 = G.has_edge(e1[0],e3[0])\n",
    "    \n",
    "    # should be 3 edges between 4 cornesrs (1 is created with extra node)\n",
    "    if(int(edge0) + int(edge1) + int(edge2) + int(edge3) != 2):\n",
    "         raise CannotExecuteProduction\n",
    "    # 'edges' with addtional node may lay near each other (cannot be on the other side of square)\n",
    "    if(int(edge0) + int(edge2) == 2):\n",
    "        raise CannotExecuteProduction\n",
    "    if(int(edge1) + int(edge3) == 2):\n",
    "        raise CannotExecuteProduction\n",
    "           \n",
    "    def getNodeBetween(e1Id, e2Id):\n",
    "        allNodes = list(G.neighbors(e1Id)) + list(G.neighbors(e2Id))\n",
    "        possibleNodes = [n for n in allNodes if n in list(G.neighbors(e1Id)) and n in list(G.neighbors(e2Id))]\n",
    "        return list(set(possibleNodes))\n",
    "    \n",
    "    possE4andE5 = list([])\n",
    "    if(not edge0):\n",
    "        possE4andE5 = possE4andE5 + getNodeBetween(e0[0],e1[0])\n",
    "    if(not edge1):\n",
    "        possE4andE5 = possE4andE5 + getNodeBetween(e0[0],e2[0])\n",
    "    if(not edge2):\n",
    "        possE4andE5 = possE4andE5 + getNodeBetween(e2[0],e3[0])\n",
    "    if(not edge3):\n",
    "        possE4andE5 = possE4andE5 + getNodeBetween(e1[0],e3[0])\n",
    " \n",
    "    # get all 'e' nodes between two nodes that does not share edge\n",
    "    maybeE4AndE5 = [ G.nodes[e] for e in possE4andE5 if G.nodes[e]['type'].lower() == 'e']\n",
    "    if(len(maybeE4AndE5) != 2):\n",
    "        raise CannotExecuteProduction\n",
    "    \n",
    "    # these are the extra nodes\n",
    "    e4 = maybeE4AndE5[0]\n",
    "    e5 = maybeE4AndE5[0]\n",
    "    \n",
    "    def checkIfHasOneOfProperPositionsOrRaise(e):\n",
    "        proper = False\n",
    "        if(not edge0):\n",
    "            if(e['pos'] == avg_pos(e0[1]['pos'], e1[1]['pos'])):\n",
    "                proper = True\n",
    "        if(not edge1):\n",
    "            if(e['pos'] != avg_pos(e0[1]['pos'], e2[1]['pos'])):\n",
    "                proper = True\n",
    "        if(not edge2):\n",
    "            if(e['pos'] != avg_pos(e2[1]['pos'], e3[1]['pos'])):\n",
    "                proper = True\n",
    "        if(not edge3):\n",
    "            if(e['pos'] != avg_pos(e1[1]['pos'], e3[1]['pos'])):\n",
    "                proper = True\n",
    "        if(not proper):\n",
    "            raise CannotExecuteProduction\n",
    "        \n",
    "    \n",
    "    #check if node has proper cordinates\n",
    "    checkIfHasOneOfProperPositionsOrRaise(e4)\n",
    "    checkIfHasOneOfProperPositionsOrRaise(e5)\n",
    "    \n",
    "    e0 = (n_id_gen(),{'pos': e0[1]['pos'],'type' : e0[1]['type']})\n",
    "    e1 = (n_id_gen(),{'pos': e1[1]['pos'],'type' : e1[1]['type']})\n",
    "    e2 = (n_id_gen(),{'pos': e2[1]['pos'],'type' : e2[1]['type']})\n",
    "    e3 = (n_id_gen(),{'pos': e3[1]['pos'],'type' : e3[1]['type']})\n",
    "\n",
    "    n0 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],e1[1]['pos']),'type':'e'})\n",
    "    n1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    n2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    n3 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    n4 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    \n",
    "    I1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I3 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I4 = (n_id_gen(),{'pos' : avg_pos(e3[1]['pos'],n2[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    # add all new edges\n",
    "    new_edges = [\n",
    "        (e0[0],n0[0]),(n0[0],e1[0]),\n",
    "        (e0[0],I1[0]),(n0[0],I1[0]), (n0[0],I2[0]),(e1[0],I2[0]),\n",
    "        (e0[0],n1[0]),(n0[0],n2[0]),(e1[0],n3[0]),\n",
    "        (n1[0],I1[0]),(n2[0],I1[0]), (n2[0],I2[0]),(n3[0],I2[0]),\n",
    "        (n1[0],n2[0]),(n2[0],n3[0]),\n",
    "        (n1[0],I3[0]),(n2[0],I3[0]), (n2[0],I4[0]),(n3[0],I4[0]),\n",
    "        (n1[0],e2[0]),(n2[0],n4[0]),(n3[0],e3[0]),\n",
    "        (e2[0],I3[0]),(n4[0],I3[0]), (n4[0],I4[0]),(e3[0],I4[0]),\n",
    "        (e2[0],n4[0]),(n4[0],e3[0]),\n",
    "    ]\n",
    "    nG.add_nodes_from([e0,e1,e2,e3,n0,n1,n2,n3,n4,I1,I2,I3,I4])\n",
    "    nG.add_edges_from(new_edges)\n",
    "    return nG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def zad_2_tests():\n",
    "    \n",
    "    def print_res(graph_layers,prod_f, prod,start_layer):\n",
    "        fig1 = plt.figure(1)\n",
    "        graph_layers.display_i_layer(start_layer)\n",
    "        fig1.suptitle(f'base {prod} graph')\n",
    "        plt.show()\n",
    "        print(f'Applying {prod} production')\n",
    "        graph_layers.add_new_layer(prod_f())\n",
    "        fig2 = plt.figure(2)\n",
    "        fig2.suptitle(f'production {prod} result')\n",
    "        graph_layers.display_i_layer(start_layer+1)\n",
    "        plt.show()\n",
    "        print('Success')\n",
    "        print()\n",
    "    \n",
    "    def prepare_graph(f=None):\n",
    "        graph_layers = Graph_layers()\n",
    "        base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "        first_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "        if f:\n",
    "            G, i_node = f(first_layer_G, base_node[0], graph_layers.get_node_id_gen())\n",
    "            graph_layers.add_new_layer(G)\n",
    "        else:\n",
    "            G, i_node = p1(first_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "            graph_layers.add_new_layer(G)\n",
    "            G = graph_layers.get_layer(1)[0]\n",
    "            G = p2(G, 1, graph_layers.get_node_id_gen())\n",
    "            graph_layers.add_new_layer(G)\n",
    "            graph_layers._layers[2][0].nodes(data=True)\n",
    "        return graph_layers,G,i_node\n",
    "        \n",
    "        \n",
    "    def pX1(G, base_node_id, n_id_gen, side_len=2, max_random_offset = 0):\n",
    "        assert(G.nodes[base_node_id]['type'].lower() == 'e' )\n",
    "        assert(len(G.nodes)==1)\n",
    "        all_new_nodes = []\n",
    "        all_new_edges = []\n",
    "        base_pos = G.nodes[base_node_id]['pos']\n",
    "        x_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "        y_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "        i_node_x, i_node_y = base_pos[0], base_pos[1]\n",
    "        i_node = (n_id_gen(), {'pos': (i_node_x+x_offset, i_node_y-y_offset), 'type': 'I','parent': -1})\n",
    "        all_new_nodes.append(i_node)\n",
    "\n",
    "        half_side_len = side_len/2\n",
    "        e_nodes = [\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y),'type': 'e'})\n",
    "        ]\n",
    "        for i in range(len(e_nodes)):\n",
    "            all_new_edges.extend([(e_nodes[i][0],e_nodes[i+1 if i + 1 < len(e_nodes) else 0][0])])\n",
    "            if i < 4:\n",
    "                all_new_edges.extend([(i_node[0],e_nodes[i][0])])\n",
    "        \n",
    "        all_new_nodes.extend(e_nodes)\n",
    "        nG = nx.Graph()\n",
    "        nG.add_nodes_from(all_new_nodes)\n",
    "        nG.add_edges_from(all_new_edges)\n",
    "        return nG, i_node\n",
    "    \n",
    "    def pX2(G, base_node_id, n_id_gen, side_len=2, max_random_offset = 0):\n",
    "        assert(G.nodes[base_node_id]['type'].lower() == 'e' )\n",
    "        assert(len(G.nodes)==1)\n",
    "        all_new_nodes = []\n",
    "        all_new_edges = []\n",
    "        base_pos = G.nodes[base_node_id]['pos']\n",
    "        x_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "        y_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "        i_node_x, i_node_y = base_pos[0], base_pos[1]\n",
    "        i_node = (n_id_gen(), {'pos': (i_node_x+x_offset, i_node_y-y_offset), 'type': 'I','parent': -1})\n",
    "        all_new_nodes.append(i_node)\n",
    "\n",
    "        half_side_len = side_len/2\n",
    "        e_nodes = [\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (7, {'pos': (i_node_x, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (6, {'pos': (i_node_x - half_side_len, i_node_y),'type': 'e'})\n",
    "        ]\n",
    "        for i in range(len(e_nodes)):\n",
    "            all_new_edges.extend([(e_nodes[i][0],e_nodes[i+1 if i + 1 < len(e_nodes) else 0][0])])\n",
    "            if i != 1 and i != 5:\n",
    "                all_new_edges.extend([(i_node[0],e_nodes[i][0])])\n",
    "\n",
    "        all_new_nodes.extend(e_nodes)\n",
    "        nG = nx.Graph()\n",
    "        nG.add_nodes_from(all_new_nodes)\n",
    "        nG.add_edges_from(all_new_edges)\n",
    "        return nG, i_node\n",
    "    \n",
    "    #TC1\n",
    "    print('p3 simple graph')\n",
    "    graph_layers, G, i_node = prepare_graph(pX1)\n",
    "    \n",
    "    print(\"Trying to use p4 on p3 graph\")\n",
    "    try:\n",
    "        p4(G, i_node[0], graph_layers.get_node_id_gen()) \n",
    "    except CannotExecuteProduction:\n",
    "        print(\"CannotExecuteProduction exception caught\")\n",
    "    else:\n",
    "        print(\"Production ran on invalid graph\")\n",
    "\n",
    "    print_res(graph_layers,lambda :p3(G, i_node[0], graph_layers.get_node_id_gen()),'p3',1)\n",
    "    \n",
    "    #TC2\n",
    "    print('p4 simple graph')\n",
    "    graph_layers, G, i_node = prepare_graph(pX2)\n",
    "    \n",
    "    print(\"Trying to use p3 on p4 graph\")\n",
    "    try:\n",
    "        p3(G, i_node[0], graph_layers.get_node_id_gen()) \n",
    "    except CannotExecuteProduction:\n",
    "        print(\"CannotExecuteProduction exception caught\")\n",
    "    else:\n",
    "        print(\"Production ran on invalid graph\")\n",
    "        \n",
    "    print_res(graph_layers,lambda :p4(G, i_node[0], graph_layers.get_node_id_gen()), 'p4',1)\n",
    "    \n",
    "    #TC3\n",
    "    print('p3 not so simple graph')\n",
    "    graph_layers, G, i_node = prepare_graph()\n",
    "    rm_edge_if_exists(G, 6, 11)\n",
    "    rm_edge_if_exists(G, 6, 10)\n",
    "    n6 = list(G.nodes(data=True))[0]\n",
    "    n10 = list(G.nodes(data=True))[4]\n",
    "    n11 = list(G.nodes(data=True))[5]\n",
    "    n19 = (19, {'pos' : avg_pos(n6[1]['pos'],n11[1]['pos']),'type':'e'})\n",
    "    n20 = (20, {'pos' : avg_pos(n6[1]['pos'],n10[1]['pos']),'type':'e'})\n",
    "    G.add_nodes_from([n19, n20])\n",
    "    G.add_edges_from([(n6[0], n19[0]), (n19[0], n11[0]), (n20[0], n6[0]), (n10[0], n20[0])])\n",
    "    \n",
    "    print(\"Trying to use p3 on p4 graph\")\n",
    "    try:\n",
    "        p3(G, 15, graph_layers.get_node_id_gen())\n",
    "    except CannotExecuteProduction:\n",
    "        print(\"CannotExecuteProduction exception caught\")\n",
    "    else:\n",
    "        print(\"Production ran on invalid graph\")\n",
    "    \n",
    "    print_res(graph_layers,lambda :p4(G, 15, graph_layers.get_node_id_gen()),'p4',2)\n",
    "    \n",
    "    #TC4\n",
    "    print('p4 not so simple graph')\n",
    "    graph_layers, G, i_node = prepare_graph()\n",
    "    rm_edge_if_exists(G, 6, 11)\n",
    "    n6 = list(G.nodes(data=True))[0]\n",
    "    n11 = list(G.nodes(data=True))[5]\n",
    "    n19 = (19, {'pos' : avg_pos(n6[1]['pos'],n11[1]['pos']),'type':'e'})\n",
    "    G.add_nodes_from([n19])\n",
    "    G.add_edges_from([(n6[0], n19[0]), (n19[0], n11[0])])\n",
    "    \n",
    "    print(\"Trying to use p4 on p3 graph\")\n",
    "    try:\n",
    "        p4(G, 15, graph_layers.get_node_id_gen())\n",
    "    except CannotExecuteProduction:\n",
    "        print(\"CannotExecuteProduction exception caught\")\n",
    "    else:\n",
    "        print(\"Production ran on invalid graph\")\n",
    "    \n",
    "    print_res(graph_layers, lambda :p3(G, 15, graph_layers.get_node_id_gen()),'p3',2)\n",
    "    \n",
    "    #TESTS ON BROKEN GRAPHS\n",
    "    np.random.seed(2137)\n",
    "    def generate_random_graph(G, base_node_id, n_id_gen, side_len=2, prob_of_node_removal=0, shuffle=True, prob_of_edge_removal=0, offset_multi=0):\n",
    "        assert(G.nodes[base_node_id]['type'].lower() == 'e' )\n",
    "        assert(len(G.nodes)==1)\n",
    "        all_new_nodes = []\n",
    "        all_new_edges = []\n",
    "        base_pos = G.nodes[base_node_id]['pos']\n",
    "        x_offset = 0\n",
    "        y_offset = 0\n",
    "        i_node_x, i_node_y = base_pos[0], base_pos[1]\n",
    "        i_node = (n_id_gen(), {'pos': (i_node_x+x_offset, i_node_y-y_offset), 'type': 'I','parent': -1})\n",
    "        all_new_nodes.append(i_node)\n",
    "\n",
    "        half_side_len = side_len/2\n",
    "        \n",
    "        def random_offset(base_val):\n",
    "            return base_val + np.sign(base_val) * offset_multi * ((np.random.random()-0.5) * 2)\n",
    "                \n",
    "        e_nodes = [\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(- half_side_len), i_node_y + random_offset(half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(half_side_len), i_node_y + random_offset(half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(half_side_len), i_node_y + random_offset(- half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(- half_side_len), i_node_y + random_offset(- half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(- half_side_len), i_node_y),'type': 'e'})\n",
    "        ] if np.random.uniform(0,1,1)[0] > 0.5 else [\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(- half_side_len), i_node_y + random_offset(half_side_len)),'type': 'e'}),\n",
    "            (7, {'pos': (i_node_x, i_node_y + random_offset(half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(half_side_len), i_node_y + random_offset(half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(half_side_len), i_node_y + random_offset(- half_side_len)),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + random_offset(- half_side_len), i_node_y + random_offset(- half_side_len)),'type': 'e'}),\n",
    "            (6, {'pos': (i_node_x - half_side_len, i_node_y),'type': 'e'})\n",
    "        ]\n",
    "        \n",
    "        if shuffle: np.random.shuffle(e_nodes)\n",
    "        e_nodes = [ b for a,b in zip(np.random.uniform(0,1,len(e_nodes)) >= prob_of_node_removal, e_nodes) if a]\n",
    "        for i in range(len(e_nodes)):\n",
    "            all_new_edges.extend([(e_nodes[i][0],e_nodes[i+1 if i + 1 < len(e_nodes) else 0][0])])\n",
    "            if i < 4:\n",
    "                all_new_edges.extend([(i_node[0],e_nodes[i][0])])\n",
    "                \n",
    "        all_new_edges= [ b for a,b in zip(np.random.uniform(0,1,len(all_new_edges)) >= prob_of_edge_removal, all_new_edges) if a]\n",
    "        all_new_nodes.extend(e_nodes)\n",
    "        nG = nx.Graph()\n",
    "        nG.add_nodes_from(all_new_nodes)\n",
    "        nG.add_edges_from(all_new_edges)\n",
    "        return nG, i_node\n",
    "    \n",
    "    def test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers, G, i_node):\n",
    "        if show_random:\n",
    "            graph_layers.display_i_layer(-1)\n",
    "            plt.show()\n",
    "        try:\n",
    "            p3(G, i_node[0], graph_layers.get_node_id_gen())\n",
    "            random_res_p3 += [True]\n",
    "            print('p3 ran')\n",
    "            graph_layers.display_i_layer(-1)\n",
    "            plt.show()\n",
    "        except CannotExecuteProduction:\n",
    "            random_res_p3 += [False]\n",
    "        try:\n",
    "            p4(G, i_node[0], graph_layers.get_node_id_gen())\n",
    "            random_res_p4 += [True]\n",
    "            print('p4 ran')\n",
    "            graph_layers.display_i_layer(-1)\n",
    "            plt.show()\n",
    "        except CannotExecuteProduction:\n",
    "            random_res_p4 += [False]\n",
    "    \n",
    "    show_random = False\n",
    "    random_res_p3 = []\n",
    "    random_res_p4 = []\n",
    "\n",
    "    print('shuffle with node removal')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_node_removal=0.6))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "    print('node removal')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_node_removal=0.4,shuffle=False))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "    print('edge removal')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_edge_removal=0.5,shuffle=False))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "    print('edge removal and node removal')    \n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_edge_removal=0.5,prob_of_node_removal=0.5,shuffle=False))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "        \n",
    "####\n",
    "    print('shuffle only')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(generate_random_graph)\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "    print('node removal shuffle and random offset')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_node_removal=0.6,shuffle=True,offset_multi=1))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "    print('edge removal shuffle and random offset')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_edge_removal=0.5,shuffle=True,offset_multi=1))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "    print('node removal edge removal shuffle and random offset')\n",
    "    for _ in range(100):\n",
    "        graph_layers, G, i_node = prepare_graph(lambda a,b,c: generate_random_graph(a,b,c,prob_of_edge_removal=0.5,prob_of_node_removal=0.5,shuffle=True,offset_multi=1))\n",
    "        test_on_broken_graph(show_random,random_res_p3,random_res_p4,graph_layers,G,i_node)\n",
    "            \n",
    "            \n",
    "    p3_res = any(random_res_p3)\n",
    "    p4_res = any(random_res_p4)\n",
    "    print(f'Has any p3 ran?: {p3_res}')\n",
    "    print(f'Has any p4 ran?: {p4_res}')\n",
    "\n",
    "    \n",
    "zad_2_tests()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import random\n",
    "\n",
    "class TestNotebook(unittest.TestCase):\n",
    "\n",
    "    def create_valid_output_layer(self):\n",
    "        graph_layers = Graph_layers()\n",
    "        id_gen = graph_layers.get_node_id_gen()\n",
    "        l2 = nx.Graph()\n",
    "        l2_edges = []\n",
    "        l2_nodes = []\n",
    "        center_x, center_y, offset, = 2, 2, -1\n",
    "        upper_i_left = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': 2})\n",
    "        lower_i_left = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': 2})\n",
    "        offset = -offset\n",
    "        upper_i_right = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': 3})\n",
    "        lower_i_right = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': 3})\n",
    "\n",
    "        l2_nodes.extend([upper_i_right, upper_i_left, lower_i_left, lower_i_right])\n",
    "\n",
    "        upper_e = (id_gen.get_id(), {'pos': (center_x, center_y + 1.5),'type': 'e'})\n",
    "        mid_e = (id_gen.get_id(), {'pos': (center_x, center_y),'type': 'e'})\n",
    "        lower_e = (id_gen.get_id(), {'pos': (center_x, center_y - 1.5),'type': 'e'})\n",
    "\n",
    "        l2_nodes.extend([upper_e, mid_e, lower_e])\n",
    "        l2_edges.extend([(upper_e[0], mid_e[0]), (lower_e[0], mid_e[0]),\n",
    "                         (lower_e[0], lower_i_left[0]),\n",
    "                         (lower_e[0], lower_i_right[0]),\n",
    "                         (lower_i_left[0], mid_e[0]),\n",
    "                         (lower_i_right[0], mid_e[0]),\n",
    "                         (upper_i_left[0], mid_e[0]),\n",
    "                         (upper_i_right[0], mid_e[0]),\n",
    "                         (upper_i_right[0], upper_e[0]),\n",
    "                         (upper_i_left[0], upper_e[0])])\n",
    "\n",
    "        l2.add_nodes_from(l2_nodes)\n",
    "        l2.add_edges_from(l2_edges)\n",
    "        graph_layers.add_new_layer(l2)\n",
    "        # graph_layers.display_i_layer(1)\n",
    "        return graph_layers.get_layer(1)[0]\n",
    "\n",
    "\n",
    "    def create_leaf_edges(self, parent, id_gen, offset, tiny_offset):\n",
    "        center_x, center_y = 2, 2\n",
    "        l2 = nx.Graph()\n",
    "        l2_edges = []\n",
    "        l2_nodes = []\n",
    "        upper_i = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': parent[0]})\n",
    "        lower_i = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': parent[0]})\n",
    "        l2_nodes.extend([upper_i, lower_i])\n",
    "\n",
    "        upper_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y + 1.5),'type': 'e'})\n",
    "        mid_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y),'type': 'e'})\n",
    "        lower_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y - 1.5),'type': 'e'})\n",
    "\n",
    "        l2_nodes.extend([upper_e, mid_e, lower_e])\n",
    "        l2_edges.extend([(upper_e[0], mid_e[0]), (lower_e[0], mid_e[0]), (lower_e[0], lower_i[0]),\n",
    "                         (lower_i[0], mid_e[0]),\n",
    "                         (upper_i[0], mid_e[0]),\n",
    "                         (upper_i[0], upper_e[0])])\n",
    "\n",
    "        l2.add_nodes_from(l2_nodes)\n",
    "        l2.add_edges_from(l2_edges)\n",
    "        return l2, [lower_i[0], upper_i[0]]\n",
    "\n",
    "    def create_valid_input_net(self):\n",
    "        graph_layers = Graph_layers()\n",
    "        side_len=2\n",
    "        parent_node_x, parent_node_y = 1, 1\n",
    "        id_gen = graph_layers.get_node_id_gen()\n",
    "        parent_node = (id_gen.get_id(), {'pos': (parent_node_x, parent_node_y), 'type': 'E','parent': -1})\n",
    "\n",
    "        half_side_len = side_len/2\n",
    "        i_nodes = [\n",
    "            (id_gen.get_id(), {'pos': (parent_node_x + half_side_len, parent_node_y - half_side_len),'type': 'I', 'parent': parent_node[0]}),\n",
    "            (id_gen.get_id(), {'pos': (parent_node_x - half_side_len, parent_node_y - half_side_len),'type': 'I', 'parent': parent_node[0]})\n",
    "        ]\n",
    "        l1_edges = []\n",
    "        for i_node in i_nodes:\n",
    "             l1_edges.extend([(i_node[0],parent_node[0])])\n",
    "\n",
    "        l1 = nx.Graph()\n",
    "        l1.add_nodes_from([parent_node])\n",
    "        l1.add_nodes_from(i_nodes)\n",
    "        l1.add_edges_from(l1_edges)\n",
    "        graph_layers.add_new_layer(l1)\n",
    "\n",
    "        center_x, center_y, offset, tiny_offset = 2, 2, -1, -0.05\n",
    "        left_graph, output_ids = self.create_leaf_edges(i_nodes[0], id_gen, offset, tiny_offset)\n",
    "        graph_layers.add_new_layer(left_graph)\n",
    "        offset = -offset\n",
    "        tiny_offset = -tiny_offset\n",
    "        right_graph, right_ids = self.create_leaf_edges(i_nodes[1], id_gen, offset, tiny_offset)\n",
    "        graph_layers.add_to_layer(2, right_graph)\n",
    "        output_ids.extend(right_ids)\n",
    "\n",
    "#         graph_layers.display_i_layer(2)\n",
    "\n",
    "        return graph_layers, output_ids\n",
    "\n",
    "    def test_p7_correct(self):\n",
    "        initial, intermediate_i_node_ids = self.create_valid_input_net()\n",
    "        output = p7(initial.get_layer(1), initial.get_layer(2), intermediate_i_node_ids, initial.get_node_id_gen())\n",
    "        assert nx.is_isomorphic(self.create_valid_output_layer(), output[1], node_match=lambda n1,n2: n1['type'] == n2['type'] and n1.get('parent', -2) == n2.get('parent', -2))\n",
    "\n",
    "\n",
    "    def test_p7_remove_parent_attribute(self):\n",
    "        layers, intermediate_i_node_ids = self.create_valid_input_net()\n",
    "        left_side = layers.get_layer(2)[0]\n",
    "        right_side = layers.get_layer(2)[1]\n",
    "        nodes = list(filter(lambda n: n in intermediate_i_node_ids, left_side.nodes))\n",
    "\n",
    "        selected_node = left_side.node[nodes[0]]\n",
    "        del selected_node['parent']\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p7(layers.get_layer(1), [left_side, right_side], intermediate_i_node_ids, layers.get_node_id_gen())\n",
    "\n",
    "\n",
    "    def test_p7_remove_random_edge(self):\n",
    "        layers, intermediate_i_node_ids = self.create_valid_input_net()\n",
    "        left_side = layers.get_layer(2)[0]\n",
    "        right_side = layers.get_layer(2)[1]\n",
    "        edges = list(left_side.edges)\n",
    "\n",
    "        # random edge choice\n",
    "        chosen_edge = random.choice(edges)\n",
    "        left_side.remove_edge(chosen_edge[0], chosen_edge[1])\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p7(layers.get_layer(1), [left_side, right_side], intermediate_i_node_ids, layers.get_node_id_gen())\n",
    "\n",
    "\n",
    "    def test_p7_remove_random_node(self):\n",
    "        layers, intermediate_i_node_ids = self.create_valid_input_net()\n",
    "        left_side = layers.get_layer(2)[0]\n",
    "        right_side = layers.get_layer(2)[1]\n",
    "        nodes = list(left_side.nodes)\n",
    "\n",
    "        # random node choice\n",
    "        left_side.remove_node(random.choice(nodes))\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p7(layers.get_layer(1), [left_side, right_side], intermediate_i_node_ids, layers.get_node_id_gen())\n",
    "\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#     e0 - m0 - e1\n",
    "#      | \\    / |\n",
    "#     m1   I0   m2 \n",
    "#      | /   \\  |\n",
    "#     e2 - - - e3\n",
    "#\n",
    "#          |\n",
    "#         \\/\n",
    "#\n",
    "#     e0 - - - m0 - - - e1\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I1    |  I2    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    m1 - - - n0 - - - m2\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I3    |  I4    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e2 - - - m3 - - - e3\n",
    "def p5(G, base_node_id, n_id_gen):\n",
    "    assert(G.nodes[base_node_id]['type'].lower() == 'i')\n",
    "    nG = nx.Graph()\n",
    "    es = list(G.neighbors(base_node_id))\n",
    "    \n",
    "    # check if I has only 4 neighbours\n",
    "    if len(es) != 4:\n",
    "         raise CannotExecuteProduction\n",
    "    \n",
    "    # assign e\n",
    "    e0, e1, e2, e3 = None, None, None, None\n",
    "    baseX, baseY = G.nodes[base_node_id]['pos']\n",
    "    for ex in es:\n",
    "        x,y = G.nodes[ex]['pos']\n",
    "        if x<baseX:\n",
    "            if y<baseY:\n",
    "                e2= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e0= (ex,G.nodes[ex])\n",
    "        else:\n",
    "            if y<baseY:\n",
    "                e3= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e1= (ex,G.nodes[ex])\n",
    "                \n",
    "    # check if all e are present\n",
    "    if not e0 or not e2 or not e2 or not e3:\n",
    "        raise CannotExecuteProduction\n",
    "    \n",
    "    # edges between e - e\n",
    "    edge0 = G.has_edge(e0[0],e1[0])\n",
    "    edge1 = G.has_edge(e0[0],e2[0])\n",
    "    edge2 = G.has_edge(e1[0],e3[0])\n",
    "    edge3 = G.has_edge(e2[0],e3[0])\n",
    "    \n",
    "    # check I - e edges\n",
    "    if not(G.has_edge(e0[0],base_node_id) and\\\n",
    "            G.has_edge(e1[0],base_node_id) and\\\n",
    "            G.has_edge(e2[0],base_node_id) and\\\n",
    "            G.has_edge(e3[0],base_node_id)\\\n",
    "            ):\n",
    "        raise CannotExecuteProduction\n",
    "        \n",
    "    # assign m0, m1, m2, m3\n",
    "    # m's are only assigned if they are e0 or e3 neighbour list and have proper x, y\n",
    "    m0, m1, m2, m3 = None, None, None, None\n",
    "    e0_neigh = list(G.neighbors(e0[0]))\n",
    "    e3_neigh = list(G.neighbors(e3[0]))\n",
    "    e0X, e0Y = e0[1]['pos']\n",
    "    e1X, e1Y = e1[1]['pos']\n",
    "    e2X, e2Y = e2[1]['pos']\n",
    "    e3X, e3Y = e3[1]['pos']\n",
    "    for node_x in e0_neigh:\n",
    "        x,y = G.nodes[node_x]['pos']\n",
    "        if x==(e0X+e1X)/2 and y==(e0Y+e1Y)/2:\n",
    "            m0 = (node_x,G.nodes[node_x])\n",
    "        if x==(e0X+e2X)/2 and y==(e0Y+e2Y)/2:\n",
    "            m1 = (node_x,G.nodes[node_x])\n",
    "    for node_x in e3_neigh:\n",
    "        x,y = G.nodes[node_x]['pos']\n",
    "        if x==(e1X+e3X)/2 and y==(e1Y+e3Y)/2:\n",
    "            m2 = (node_x,G.nodes[node_x])\n",
    "        if x==(e2X+e3X)/2 and y==(e2Y+e3Y)/2:\n",
    "            m3 = (node_x,G.nodes[node_x])\n",
    "    \n",
    "    # check if all three m present\n",
    "    m_list = [m0, m1, m2, m3]\n",
    "    none_m_num = sum(x is None for x in m_list)\n",
    "    if none_m_num != 1:\n",
    "        raise CannotExecuteProduction\n",
    "        \n",
    "    # check if m not present the e-e edge exists\n",
    "    if m0 is None and not edge0:\n",
    "        raise CannotExecuteProduction\n",
    "    if m1 is None and not edge1:\n",
    "        raise CannotExecuteProduction\n",
    "    if m2 is None and not edge2:\n",
    "        raise CannotExecuteProduction\n",
    "    if m3 is None and not edge3:\n",
    "        raise CannotExecuteProduction\n",
    "        \n",
    "    # prepare all new verticies accord to map above\n",
    "    e0 = (n_id_gen(),{'pos': e0[1]['pos'],'type' : e0[1]['type']})\n",
    "    e1 = (n_id_gen(),{'pos': e1[1]['pos'],'type' : e1[1]['type']})\n",
    "    e2 = (n_id_gen(),{'pos': e2[1]['pos'],'type' : e2[1]['type']})\n",
    "    e3 = (n_id_gen(),{'pos': e3[1]['pos'],'type' : e3[1]['type']})\n",
    "\n",
    "    # generate m if not exists\n",
    "    if m0 is None:\n",
    "        m0 = (n_id_gen(),{'pos': avg_pos(e0[1]['pos'],e1[1]['pos']),'type':'e'})\n",
    "    else:\n",
    "        m0 = (n_id_gen(),{'pos': m0[1]['pos'],'type': m0[1]['type']})\n",
    "    \n",
    "    if m1 is None:\n",
    "        m1 = (n_id_gen(),{'pos': avg_pos(e0[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    else:\n",
    "        m1 = (n_id_gen(),{'pos': m1[1]['pos'],'type': m1[1]['type']})\n",
    "    \n",
    "    if m2 is None:\n",
    "        m2 = (n_id_gen(),{'pos': avg_pos(e1[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    else:\n",
    "        m2 = (n_id_gen(),{'pos': m2[1]['pos'],'type': m2[1]['type']})\n",
    "    \n",
    "    if m3 is None:\n",
    "        m3 = (n_id_gen(),{'pos': avg_pos(e2[1]['pos'],e3[1]['pos']),'type':'e'})\n",
    "    else:\n",
    "        m3 = (n_id_gen(),{'pos': m3[1]['pos'],'type': m3[1]['type']})\n",
    "        \n",
    "    n0 = (n_id_gen(),{'pos': avg_pos(e1[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "    \n",
    "    I1 = (n_id_gen(),{'pos': avg_pos(e0[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I2 = (n_id_gen(),{'pos': avg_pos(e1[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I3 = (n_id_gen(),{'pos': avg_pos(e2[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I4 = (n_id_gen(),{'pos': avg_pos(e3[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    \n",
    "    # add all new edges\n",
    "    new_edges = [\n",
    "        (e0[0],m0[0]),(m0[0],e1[0]),\n",
    "        (e0[0],I1[0]),(m0[0],I1[0]), (m0[0],I2[0]),(e1[0],I2[0]),\n",
    "        (e0[0],m1[0]),(m0[0],n0[0]),(e1[0],m2[0]),\n",
    "        (m1[0],I1[0]),(n0[0],I1[0]), (n0[0],I2[0]),(m2[0],I2[0]),\n",
    "        (m1[0],n0[0]),(n0[0],m2[0]),\n",
    "        (m1[0],I3[0]),(n0[0],I3[0]), (n0[0],I4[0]),(m2[0],I4[0]),\n",
    "        (m1[0],e2[0]),(n0[0],m3[0]),(m2[0],e3[0]),\n",
    "        (e2[0],I3[0]),(m3[0],I3[0]), (m3[0],I4[0]),(e3[0],I4[0]),\n",
    "        (e2[0],m3[0]),(m3[0],e3[0]),\n",
    "    ]\n",
    "    nG.add_nodes_from([e0,e1,e2,e3,m0,m1,m2,n0,m3,I1,I2,I3,I4])\n",
    "    nG.add_edges_from(new_edges)\n",
    "    return nG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "graph_layers_p5 = Graph_layers()\n",
    "base_node_p5 = list(graph_layers_p5.get_layer(0)[0].nodes(data=True))[0]\n",
    "#indexing from 0 \n",
    "first_layer_G_p5 = graph_layers_p5.get_layer(0)[0].copy()\n",
    "\n",
    "#apply p1 production\n",
    "G_p5, i_node = p1(first_layer_G_p5, base_node_p5[0], graph_layers_p5.get_node_id_gen()) \n",
    "\n",
    "#temper the graph\n",
    "rm_edge_if_exists(G_p5, 2, 3)\n",
    "rm_edge_if_exists(G_p5, 2, 5)\n",
    "rm_edge_if_exists(G_p5, 3, 4)\n",
    "e0 = (2, G_p5.nodes[2])\n",
    "e1 = (3, G_p5.nodes[3])\n",
    "e2 = (5, G_p5.nodes[5])\n",
    "e3 = (4, G_p5.nodes[4])\n",
    "m0 = (111,{'pos' : avg_pos(e0[1]['pos'],e1[1]['pos']),'type': 'e'})\n",
    "m1 = (222,{'pos' : avg_pos(e0[1]['pos'],e2[1]['pos']),'type': 'e'})\n",
    "m2 = (333,{'pos' : avg_pos(e1[1]['pos'],e3[1]['pos']),'type': 'e'})\n",
    "new_edges = [\n",
    "     (e0[0], m1[0]), (m1[0], e2[0]),\n",
    "     (e0[0], m0[0]), (m0[0], e1[0]),\n",
    "     (e1[0], m2[0]), (m2[0], e3[0]),\n",
    "    ]\n",
    "G_p5.add_nodes_from([m0,m1,m2])\n",
    "G_p5.add_edges_from(new_edges)\n",
    "graph_layers_p5.add_new_layer(G_p5)\n",
    "graph_layers_p5.display_i_layer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#apply p5 production\n",
    "G_p5 = graph_layers_p5.get_layer(1)[0]\n",
    "nG_p5 = p5(G_p5, 1, graph_layers_p5.get_node_id_gen())\n",
    "graph_layers_p5.add_new_layer(nG_p5)\n",
    "graph_layers_p5._layers[2][0].nodes(data=True)\n",
    "graph_layers_p5.display_i_layer(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# p5 tests\n",
    "import unittest\n",
    "from collections import defaultdict\n",
    "\n",
    "def run_test_p5():\n",
    "    idc = Id_creator()\n",
    "    \n",
    "    # do głupiego debugowania\n",
    "    def draw(g):\n",
    "        pos = nx.get_node_attributes(g, 'pos')\n",
    "        nx.draw_networkx(g, pos)\n",
    "    \n",
    "    # funkcje pomocniczne, klasa z testami poniżej\n",
    "    # returns Graph, I id, list of e ids\n",
    "    def make_base_graph():\n",
    "        ids = [idc() for x in range(5)]\n",
    "        nodes = [[i, {'type': 'e'}] for i in ids]\n",
    "        i = nodes[0]\n",
    "        es = nodes[1:]\n",
    "        i[1]['type'] = 'i'\n",
    "        \n",
    "        edges = []\n",
    "        pairs = [[0,1],[0,2],[1,3],[2,3]]\n",
    "\n",
    "        for e in es:\n",
    "            edges.append((i[0], e[0]))\n",
    "\n",
    "        for a,b in pairs:\n",
    "            edges.append((es[a][0], es[b][0]))\n",
    "        \n",
    "        i[1]['pos'] = (0,0)\n",
    "        poses = [(-1, 1), (1, 1), (-1, -1), (1, -1)]\n",
    "        for idx, pos in enumerate(poses):\n",
    "            es[idx][1]['pos'] = pos\n",
    "        \n",
    "        g = nx.Graph()\n",
    "        g.add_nodes_from(nodes)\n",
    "        g.add_edges_from(edges)\n",
    "\n",
    "        return g, ids[0], ids[1:]\n",
    "    \n",
    "    def make_basic_graph(edges=[[0,1], [0,2], [1,3]]):\n",
    "        g, i, es = make_base_graph()\n",
    "        for ai, bi in edges:\n",
    "            a, b = es[ai], es[bi]\n",
    "            add_m_between(g, a, b)\n",
    "        return (g, i, es)\n",
    "    \n",
    "    def add_m_between(g, ia, ib):\n",
    "        m = idc()\n",
    "        a = g.nodes[ia]['pos']\n",
    "        b = g.nodes[ib]['pos']\n",
    "        g.add_nodes_from([(m, {'type': 'e', 'pos': avg_pos(a,b)})])\n",
    "        g.add_edges_from([[ia,m], [m,ib]])\n",
    "        g.remove_edge(ia, ib)\n",
    "        return m\n",
    "\n",
    "\n",
    "    class TestProduction5(unittest.TestCase):\n",
    "        def is_result_ok(self, g, base_node_id):\n",
    "            def where_nodes(attr, t, nodes=None):\n",
    "                ns = g.nodes if nodes == None else nodes\n",
    "                attrs = nx.get_node_attributes(g, attr)\n",
    "                return [n for n in ns if attrs[n] == t]\n",
    "\n",
    "            def find_nodes_between(nodes):\n",
    "                # for a given set of nodes [e0, e1, e2, ...]\n",
    "                # find nodes (of type 'e') that are neighbors of exactly two of these nodes\n",
    "                m_scores = defaultdict(int)\n",
    "                for e in nodes:\n",
    "                    for neighbor in g.neighbors(e):\n",
    "                        if g.nodes[neighbor]['type'] == 'e':\n",
    "                            m_scores[neighbor] += 1\n",
    "                ms = [k for k, v in m_scores.items() if v == 2]\n",
    "                return ms\n",
    "\n",
    "            def is_node_between(m, a, b):\n",
    "                expected_pos = avg_pos(g.nodes[a]['pos'], g.nodes[b]['pos'])\n",
    "                return expected_pos == g.nodes[m]['pos']\n",
    "    \n",
    "            Is = where_nodes('parent', base_node_id, nodes=where_nodes('type', 'I'))\n",
    "\n",
    "            # dla każdej ćwiartki\n",
    "            for I in Is:\n",
    "                es = list(g.neighbors(I))\n",
    "                self.assertEqual(len(es), 4)\n",
    "                posc = lambda c: sum(g.nodes[n]['pos'][c] for n in es)/4\n",
    "                # czy I znajduje się w średniej współrzędnych wszystkich sąsiadów\n",
    "                self.assertEqual(g.nodes[I]['pos'], (posc(0), posc(1)))\n",
    "\n",
    "            # czy pary I mają jednego/dwóch wspólnych sąsiadów\n",
    "            for a, b in [[0,1], [0,2], [2,3], [1,3]]:\n",
    "                I1, I2 = Is[a], Is[b]\n",
    "                self.assertEqual(2, len(find_nodes_between([I1, I2])))\n",
    "            for a, b in [[0,3], [1,2]]:\n",
    "                I1, I2 = Is[a], Is[b]\n",
    "                between = find_nodes_between([I1, I2])\n",
    "                self.assertEqual(1, len(between))\n",
    "                self.assertTrue(is_node_between(between[0], I1, I2))\n",
    "            \n",
    "            # czy I razem mają 9 e\n",
    "            eses = [list(g.neighbors(I)) for I in Is]\n",
    "            # flatten\n",
    "            eses = [item for items in eses for item in items]\n",
    "            eses = list(set(eses))\n",
    "            self.assertEqual(len(eses), 9)\n",
    "        \n",
    "\n",
    "        def test_super_basic(self):\n",
    "            # najprostszy test case\n",
    "            g, i, es = make_basic_graph()\n",
    "            p5_result = p5(g, i, idc)\n",
    "            self.is_result_ok(p5_result, i)\n",
    "            \n",
    "            # odnajdź node po pozycji + asercja że istnieje dokładnie jeden\n",
    "            def find_node(graph, pos):\n",
    "                attrs = nx.get_node_attributes(graph, 'pos')\n",
    "                results = [k for k, v in attrs.items() if v == pos]\n",
    "                self.assertEqual(len(results), 1)\n",
    "                return results[0]\n",
    "\n",
    "            # sprawdzenie kilku nodów (górnych) i porównanie do lewej strony\n",
    "            poses = nx.get_node_attributes(p5_result, 'pos')\n",
    "            cord = lambda n: list(map(lambda pos: pos[n], poses.values()))\n",
    "            topleft = find_node(p5_result, (min(cord(0)), max(cord(1))))\n",
    "            topright = find_node(p5_result, (max(cord(0)), max(cord(1))))\n",
    "            self.assertFalse(topleft in p5_result.neighbors(topright))\n",
    "            \n",
    "            # górny środkowy:\n",
    "            topmid = find_node(p5_result, avg_pos(p5_result.nodes[topleft]['pos'], p5_result.nodes[topright]['pos']))\n",
    "            self.assertTrue(topmid in p5_result.neighbors(topleft))\n",
    "            self.assertTrue(topmid in p5_result.neighbors(topright))\n",
    "            \n",
    "            # czy istnieją odpowidniki po lewej stronie produkcji:\n",
    "            \n",
    "            org_topleft = find_node(g, p5_result.nodes[topleft]['pos'])\n",
    "            org_topright = find_node(g, p5_result.nodes[topright]['pos'])\n",
    "            org_topright = find_node(g, p5_result.nodes[topmid]['pos'])\n",
    "\n",
    "        def test_subgraph_passes(self):\n",
    "            # czy aplikuje dla podgrafu\n",
    "            # dodaję ekstra wierzchołek i krawędź w kilku miejscach\n",
    "            def add_to(g, n):\n",
    "                some_e_id = n\n",
    "                new_id = idc()\n",
    "                g.add_nodes_from([(new_id, {'type': 'e', 'pos': (0, 0.5)})])\n",
    "                g.add_edge(new_id, some_e_id)\n",
    "\n",
    "            for ei in range(4):\n",
    "                g, i, es = make_base_graph()\n",
    "\n",
    "                for ai, bi in [[0,1], [0,2], [1,3]]:\n",
    "                    a, b = es[ai], es[bi]\n",
    "                    add_m_between(g, a, b)\n",
    "                add_to(g, es[ei])\n",
    "                self.is_result_ok(p5(g, i, idc), i)\n",
    "\n",
    "            for m in range(3):\n",
    "                g, i, es = make_base_graph()\n",
    "                ms = []\n",
    "                for ai, bi in [[0,1], [0,2], [1,3]]:\n",
    "                    a, b = es[ai], es[bi]\n",
    "                    ms.append(add_m_between(g, a, b))\n",
    "                add_to(g, ms[m])\n",
    "                self.is_result_ok(p5(g, i, idc), i)\n",
    "            g, i, es = make_base_graph()\n",
    "            for ai, bi in [[0,1], [0,2], [1,3]]:\n",
    "                a, b = es[ai], es[bi]\n",
    "                ms.append(add_m_between(g, a, b))\n",
    "            # kilka ekstra wierzchołków, jeden ekstra to każdego narożnika\n",
    "            for e in es:\n",
    "                add_to(g, e)\n",
    "            self.is_result_ok(p5(g, i, idc), i)\n",
    "\n",
    "\n",
    "        def test_sides(self):\n",
    "            g, i, es = make_basic_graph(edges=[[0,1], [0,2], [2,3]])\n",
    "            self.is_result_ok(p5(g, i, idc), i)\n",
    "            g, i, es = make_basic_graph(edges=[[0,1], [1,3], [2,3]])\n",
    "            self.is_result_ok(p5(g, i, idc), i)\n",
    "\n",
    "        def test_upsidedown(self):\n",
    "            g, i, es = make_basic_graph(edges=[[0,2], [2,3], [1,3]])\n",
    "            self.is_result_ok(p5(g, i, idc), i)\n",
    "\n",
    "        # testy sprawdzające czy produkcja się nie wykona kiedy nie powinna:\n",
    "        \n",
    "        def test_complete(self):\n",
    "            # przypadek dla grafu do lewej strony producji 6\n",
    "            g, i, es = make_basic_graph(edges=[[0,1], [0,2], [2,3], [1,3]])\n",
    "            with self.assertRaises(CannotExecuteProduction):\n",
    "                p5(g, i, idc)\n",
    "                \n",
    "        def test_mislabel(self):\n",
    "            # na obecnosc etykiety type: e\n",
    "            g, i, es = make_base_graph()\n",
    "            for ei in range(4):\n",
    "                e = es[ei]\n",
    "                g.nodes[e]['type'] = 'qweqweqwe'\n",
    "                with self.assertRaises(CannotExecuteProduction):\n",
    "                    p5(g, i, idc)\n",
    "\n",
    "        def test_missing_e(self):\n",
    "            # po usunieciu node\n",
    "            g, i, es = make_base_graph()\n",
    "            for ei in range(4):\n",
    "                g.remove_node(es[ei])\n",
    "                with self.assertRaises(CannotExecuteProduction):\n",
    "                    p5(g, i, idc)\n",
    "\n",
    "\n",
    "        def test_missing_m(self):\n",
    "            # przypadek dobry dla produkcji 4\n",
    "            g, i, es = make_basic_graph(edges=[[0,2], [2,3]])\n",
    "            with self.assertRaises(CannotExecuteProduction):\n",
    "                p5(g, i, idc)\n",
    "\n",
    "        def test_missing_edges(self):\n",
    "            # brak krawędzi między I a e\n",
    "            g, i, es = make_basic_graph()\n",
    "            g.remove_edge(i, es[0])\n",
    "            with self.assertRaises(CannotExecuteProduction):\n",
    "                p5(g, i, idc)\n",
    "    \n",
    "            # brak krawędzi między e a e\n",
    "            g, i, es = make_basic_graph()\n",
    "            g.remove_edge(es[2], es[3])\n",
    "            with self.assertRaises(CannotExecuteProduction):\n",
    "                p5(g, i, idc)\n",
    "                \n",
    "        def test_wrong_coords_e(self):\n",
    "            g, i, es = make_basic_graph()\n",
    "            g.nodes[es[0]]['pos'] = (10.0, 20.0)\n",
    "            with self.assertRaises(CannotExecuteProduction):\n",
    "                p5(g, i, idc)\n",
    "                \n",
    "        def test_wrong_coords_i(self):\n",
    "            g, i, es = make_basic_graph()\n",
    "            g.nodes[i]['pos'] = (10.0, 20.0)\n",
    "            with self.assertRaises(CannotExecuteProduction):\n",
    "                p5(g, i, idc)\n",
    "\n",
    "    suite = unittest.defaultTestLoader.loadTestsFromTestCase(TestProduction5)\n",
    "    unittest.TextTestRunner().run(suite)\n",
    "run_test_p5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def p8(top_layer, lower_layer, base_node_ids, n_id_gen):\n",
    "    assert len(base_node_ids) == 4\n",
    "\n",
    "    # step 1) select lower graph \n",
    "    lower_graphs = { G for n_id in base_node_ids for G in lower_layer if G.has_node(n_id) }\n",
    "      \n",
    "    assert len(lower_graphs) == 1\n",
    "    lower_graph, = lower_graphs\n",
    "\n",
    "    assert all(n_id in lower_graph.nodes for n_id in base_node_ids)\n",
    "    \n",
    "    # step 2) select lower i nodes and their parents\n",
    "    lower_is, = group_nodes_by_attr(lower_graph, base_node_ids, 'type', str.lower).select('i')\n",
    "\n",
    "    grouping = group_nodes_by_attr(lower_graph, lower_is, 'parent')\n",
    "    assert len(grouping) == 2\n",
    "    \n",
    "    (top_i1, lower_i1s), (top_i2, lower_i2s) = grouping.items()\n",
    "    assert len(lower_i1s) == 2\n",
    "    assert len(lower_i2s) == 2\n",
    "    \n",
    "    # step 3) select top graph\n",
    "    top_graphs = { G for n_id in (top_i1, top_i2) for G in top_layer if G.has_node(n_id) }\n",
    "    assert len(top_graphs) == 1\n",
    "    top_graph, = top_graphs\n",
    "    \n",
    "    # step 4) validate top_layer connections\n",
    "    assert len(find_common_e_neighbors(top_graph, top_i1, top_i2)) >= 1\n",
    "    \n",
    "    # step 5) find lower e nodes candidates\n",
    "    e1_candidates = find_common_e_neighbors(lower_graph, *lower_i1s)\n",
    "    e2_candidates = find_common_e_neighbors(lower_graph, *lower_i2s)\n",
    "\n",
    "    e0_candidates = find_common_group_e_neighbors(lower_graph, lower_i1s, lower_i2s, e1_candidates, e2_candidates)\n",
    "\n",
    "    e3_candidates = find_common_group_e_neighbors(lower_graph, lower_i1s, e1_candidates) - e0_candidates\n",
    "    e4_candidates = find_common_group_e_neighbors(lower_graph, lower_i2s, e2_candidates) - e0_candidates\n",
    "\n",
    "    # step 6) solve constraints on es\n",
    "    pos = lambda n_id: lower_graph.nodes[n_id]['pos']\n",
    "\n",
    "    solutions = [\n",
    "        (e0, e1, e2, e3, e4) \n",
    "        for e0 in e0_candidates \n",
    "        for e1 in e1_candidates \n",
    "        for e2 in e2_candidates \n",
    "        for e3 in e3_candidates \n",
    "        for e4 in e4_candidates\n",
    "        if isapprox(pos(e1), pos(e2))\n",
    "        and isapprox(pos(e3), pos(e4))\n",
    "        and isapprox(pos(e1), avg_pos(pos(e0), pos(e3)))\n",
    "    ]\n",
    "    assert len(solutions) == 1, \"can not apply production or production is ambiguous\"\n",
    "    (e0, e1, e2, e3, e4), = solutions\n",
    "\n",
    "    # step 7) create graph (merge e1, e2 and e3, e4)\n",
    "    new_graph = nx.contracted_nodes(lower_graph, e1, e2)\n",
    "    new_graph = nx.contracted_nodes(new_graph, e3, e4)\n",
    "    return new_graph, lower_graph\n",
    "\n",
    "def apply_P8(parent_layer, child_layer, base_node_ids, n_id_gen):\n",
    "    new_graph, old_graph = p8(parent_layer, child_layer, base_node_ids, n_id_gen)\n",
    "    child_layer.remove(old_graph)\n",
    "    child_layer.append(new_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class P8Tests(unittest.TestCase):\n",
    "    def valid_input_components(self):\n",
    "        top_nodes = [\n",
    "            (1,{'pos': (0,0),'type' : 'e'}),\n",
    "            (2,{'pos': (-1,0),'type' : 'i'}),\n",
    "            (3,{'pos': (1,0),'type' : 'i'})\n",
    "        ]\n",
    "        top_edges = [(1, 2), (1, 3)]\n",
    "        lower_nodes = [\n",
    "            (20, {'pos': (0, 1), 'type': 'e'}),\n",
    "            (21, {'pos': (0, 0), 'type': 'e'}),\n",
    "            (23, {'pos': (0, 0), 'type': 'e'}),\n",
    "            (22, {'pos': (0,-1), 'type': 'e'}),\n",
    "            (24, {'pos': (0,-1), 'type': 'e'}),\n",
    "\n",
    "            (10, {'pos': (-0.5,0.5), 'type': 'i', 'parent': 2}),\n",
    "            (12, {'pos': ( 0.5,0.5), 'type': 'i', 'parent': 3}),\n",
    "\n",
    "            (11, {'pos': (-0.5,-0.5), 'type': 'i', 'parent': 2}),\n",
    "            (13, {'pos': ( 0.5,-0.5), 'type': 'i', 'parent': 3}),\n",
    "        ]\n",
    "        lower_edges = [\n",
    "            (20,21), (20,23), \n",
    "            (21,22), (23,24),\n",
    "            (10,20), (10,21),\n",
    "            (12,20), (12,23),\n",
    "            (11,21), (11,22),\n",
    "            (13,23), (13,24),\n",
    "        ]\n",
    "        return top_nodes, top_edges, lower_nodes, lower_edges\n",
    "        \n",
    "    def valid_output_components(self):\n",
    "        top_nodes = [\n",
    "            (1,{'pos': (0,0),'type' : 'e'}),\n",
    "            (2,{'pos': (-1,0),'type' : 'i'}),\n",
    "            (3,{'pos': (1,0),'type' : 'i'})\n",
    "        ]\n",
    "        top_edges = [(1, 2), (1, 3)]\n",
    "        lower_nodes = [\n",
    "            (20, {'pos': (0, 1), 'type': 'e'}),\n",
    "            (21, {'pos': (0, 0), 'type': 'e'}),\n",
    "            (22, {'pos': (0,-1), 'type': 'e'}),\n",
    "\n",
    "            (10, {'pos': (-0.5,0.5), 'type': 'i', 'parent': 2}),\n",
    "            (12, {'pos': ( 0.5,0.5), 'type': 'i', 'parent': 3}),\n",
    "\n",
    "            (11, {'pos': (-0.5,-0.5), 'type': 'i', 'parent': 2}),\n",
    "            (13, {'pos': ( 0.5,-0.5), 'type': 'i', 'parent': 3}),\n",
    "        ]\n",
    "        lower_edges = [\n",
    "            (20,21), (20,21), \n",
    "            (21,22),\n",
    "            (10,20), (10,21),\n",
    "            (12,20), (12,21),\n",
    "            (11,21), (11,22),\n",
    "            (13,21), (13,22),\n",
    "        ]\n",
    "        return top_nodes, top_edges, lower_nodes, lower_edges   \n",
    "        \n",
    "    def create_graph(self, top_nodes, top_edges, lower_nodes, lower_edges):\n",
    "        graph = Graph_layers()\n",
    "        top_graph = nx.Graph()\n",
    "        top_graph.add_nodes_from(top_nodes)\n",
    "        top_graph.add_edges_from(top_edges)\n",
    "        graph.add_new_layer(top_graph)\n",
    "        \n",
    "        lower_graph = nx.Graph()\n",
    "        lower_graph.add_nodes_from(lower_nodes)\n",
    "        lower_graph.add_edges_from(lower_edges)\n",
    "        graph.add_new_layer(lower_graph)\n",
    "\n",
    "        return graph\n",
    "    \n",
    "    def test_applying_production_to_minimum_valid_graph(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        graph = self.create_graph(top_nodes, top_edges, lower_nodes, lower_edges)\n",
    "    \n",
    "        apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())\n",
    "    \n",
    "        valid_output = self.create_graph(*self.valid_output_components())\n",
    "        self.assertTrue(nx.is_isomorphic(graph.get_layer(2)[0], valid_output.get_layer(2)[0], node_match=lambda n1,n2: n1['type'] == n2['type'] and n1.get('parent', -2) == n2.get('parent', -2)))\n",
    "    \n",
    "    def test_should_fail_without_node(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        for node in lower_nodes:\n",
    "            lower_nodes_missing = list(lower_nodes)\n",
    "            lower_nodes_missing.remove(node)\n",
    "            n_id, _ = node\n",
    "            lower_edges_missing = [edge for edge in lower_edges if n_id not in edge]\n",
    "\n",
    "            graph = self.create_graph(top_nodes, top_edges, lower_nodes_missing, lower_edges_missing)\n",
    "            with self.assertRaises(AssertionError):\n",
    "                apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())\n",
    "    \n",
    "    def test_should_fail_without_edge(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        for edge in lower_edges:\n",
    "            lower_edges_missing = list(lower_edges)\n",
    "            lower_edges_missing.remove(edge)\n",
    "        \n",
    "            graph = self.create_graph(top_nodes, top_edges, lower_nodes, lower_edges_missing)\n",
    "            with self.assertRaises(AssertionError):\n",
    "                apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())\n",
    "    \n",
    "    def test_should_fail_with_invalid_lavel(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        \n",
    "        for i, (n_id, meta) in enumerate(lower_nodes):\n",
    "            lower_nodes_invalid = deepcopy(lower_nodes)\n",
    "            del lower_nodes_invalid[i]\n",
    "            meta['type'] = 'i' if meta['type'] == 'e' else 'e'\n",
    "            lower_nodes_invalid.append((n_id, meta))\n",
    "\n",
    "            graph = self.create_graph(top_nodes, top_edges, lower_nodes_invalid, lower_edges)\n",
    "            with self.assertRaises(AssertionError):\n",
    "                apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())           \n",
    "    \n",
    "    def test_should_fail_with_invalid_label(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        \n",
    "        for i, (n_id, meta) in enumerate(lower_nodes):\n",
    "            lower_nodes_invalid = deepcopy(lower_nodes)\n",
    "            del lower_nodes_invalid[i]\n",
    "            meta['type'] = 'i' if meta['type'] == 'e' else 'e'\n",
    "            lower_nodes_invalid.append((n_id, meta))\n",
    "\n",
    "            graph = self.create_graph(top_nodes, top_edges, lower_nodes_invalid, lower_edges)\n",
    "            with self.assertRaises(AssertionError):\n",
    "                apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())   \n",
    "        \n",
    "    def test_should_fail_with_invalid_coords(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        lower_nodes.remove((20, {'pos': (0, 1), 'type': 'e'}))\n",
    "        lower_nodes.append((20, {'pos': (0, 100), 'type': 'e'}))\n",
    "        \n",
    "        graph = self.create_graph(top_nodes, top_edges, lower_nodes, lower_edges)\n",
    "        with self.assertRaises(AssertionError):\n",
    "            apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())  \n",
    "    \n",
    "    def test_should_work_as_subgraph(self):\n",
    "        top_nodes, top_edges, lower_nodes, lower_edges = self.valid_input_components()\n",
    "        lower_nodes += [\n",
    "            (14, {'pos': (-0.5,0.5), 'type': 'i', 'parent': 2}),\n",
    "            (15, {'pos': (-0.5,0.5), 'type': 'i', 'parent': 3}),\n",
    "        ]\n",
    "        lower_edges += [(20, 15), (20, 14), (15, 13), (24, 15)]\n",
    "        graph = self.create_graph(top_nodes, top_edges, lower_nodes, lower_edges)\n",
    "        apply_P8(graph.get_layer(1), graph.get_layer(2), [10,11,12,13], graph.get_node_id_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#  P(6)\n",
    "#     e0 - m0 - e1\n",
    "#      | \\    / |\n",
    "#     m1   I0   m2\n",
    "#      | /   \\  |\n",
    "#     e2 - m3 - e3\n",
    "#\n",
    "#          |\n",
    "#         \\/\n",
    "#\n",
    "#     e0 - - - m0 - - - e1\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I1    |  I2    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    m1 - - - n0 - - - m2\n",
    "#     | \\    / | \\    / |\n",
    "#     |  I3    |  I4    |\n",
    "#     | /   \\  | /   \\  |\n",
    "#    e2 - - - m3 - - - e3\n",
    "\n",
    "def p6(G, base_node_id, n_id_gen):\n",
    "    assert(G.nodes[base_node_id]['type'].lower() == 'i')\n",
    "    nG = nx.Graph()\n",
    "    es = list(G.neighbors(base_node_id))\n",
    "\n",
    "    # check if I has 4 neighbours\n",
    "    if len(es) != 4:\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    # assign e\n",
    "    e0, e1, e2, e3 = None, None, None, None\n",
    "    baseX, baseY = G.nodes[base_node_id]['pos']\n",
    "    for ex in es:\n",
    "        x,y = G.nodes[ex]['pos']\n",
    "        if x<baseX:\n",
    "            if y<baseY:\n",
    "                e2= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e0= (ex,G.nodes[ex])\n",
    "        else:\n",
    "            if y<baseY:\n",
    "                e3= (ex,G.nodes[ex])\n",
    "            if y>baseY:\n",
    "                e1= (ex,G.nodes[ex])\n",
    "\n",
    "    e0_neigh = list(G.neighbors(e0[0]))\n",
    "    e1_neigh = list(G.neighbors(e1[0]))\n",
    "    e2_neigh = list(G.neighbors(e2[0]))\n",
    "    e3_neigh = list(G.neighbors(e3[0]))\n",
    "\n",
    "    # assign m & check m (x,y)\n",
    "    m0, m1, m2, m3 = None, None, None, None\n",
    "    e0X, e0Y = e0[1]['pos']\n",
    "    e1X, e1Y = e1[1]['pos']\n",
    "    e2X, e2Y = e2[1]['pos']\n",
    "    e3X, e3Y = e3[1]['pos']\n",
    "    for node_x in e0_neigh:\n",
    "        x,y = G.nodes[node_x]['pos']\n",
    "        if x==(e0X+e1X)/2 and y==(e0Y+e1Y)/2:\n",
    "            m0 = (node_x,G.nodes[node_x])\n",
    "        if x==(e0X+e2X)/2 and y==(e0Y+e2Y)/2:\n",
    "            m1 = (node_x,G.nodes[node_x])\n",
    "    for node_x in e1_neigh:\n",
    "        x,y = G.nodes[node_x]['pos']\n",
    "        if x==(e1X+e3X)/2 and y==(e1Y+e3Y)/2:\n",
    "            m2 = (node_x,G.nodes[node_x])\n",
    "    for node_x in e2_neigh:\n",
    "        x,y = G.nodes[node_x]['pos']\n",
    "        if x==(e2X+e3X)/2 and y==(e2Y+e3Y)/2:\n",
    "            m3 = (node_x,G.nodes[node_x])\n",
    "    if m0 is None or m1 is None or m2 is None or m3 is None:\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    # check if each m has 2 neighbours\n",
    "    m0_neigh = list(G.neighbors(m0[0]))\n",
    "    m1_neigh = list(G.neighbors(m1[0]))\n",
    "    m2_neigh = list(G.neighbors(m2[0]))\n",
    "    m3_neigh = list(G.neighbors(m3[0]))\n",
    "    if (len(m0_neigh) != 2 or\n",
    "        len(m1_neigh) != 2 or\n",
    "        len(m2_neigh) != 2 or\n",
    "        len(m3_neigh) != 2):\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    # check I0 edges\n",
    "    if not(G.has_edge(e0[0],base_node_id) and\n",
    "            G.has_edge(e1[0],base_node_id) and\n",
    "            G.has_edge(e2[0],base_node_id) and\n",
    "            G.has_edge(e3[0],base_node_id)\n",
    "            ):\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    # check each e and m edges\n",
    "    if not(G.has_edge(e0[0], m0[0]) and\n",
    "            G.has_edge(e0[0], m1[0]) and\n",
    "            G.has_edge(e1[0], m0[0]) and\n",
    "            G.has_edge(e1[0], m2[0]) and\n",
    "            G.has_edge(e2[0], m1[0]) and\n",
    "            G.has_edge(e2[0], m3[0]) and\n",
    "            G.has_edge(e3[0], m2[0]) and\n",
    "            G.has_edge(e3[0], m3[0])\n",
    "            ):\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "    #prepare all new vertices according to map above\n",
    "    e0 = (n_id_gen(),{'pos': e0[1]['pos'],'type' : e0[1]['type']})\n",
    "    e1 = (n_id_gen(),{'pos': e1[1]['pos'],'type' : e1[1]['type']})\n",
    "    e2 = (n_id_gen(),{'pos': e2[1]['pos'],'type' : e2[1]['type']})\n",
    "    e3 = (n_id_gen(),{'pos': e3[1]['pos'],'type' : e3[1]['type']})\n",
    "\n",
    "    m0 = (n_id_gen(),{'pos' : m0[1]['pos'],'type': m0[1]['type']})\n",
    "    m1 = (n_id_gen(),{'pos' : m1[1]['pos'],'type': m1[1]['type']})\n",
    "    m2 = (n_id_gen(),{'pos' : m2[1]['pos'],'type': m2[1]['type']})\n",
    "    m3 = (n_id_gen(),{'pos' : m3[1]['pos'],'type': m3[1]['type']})\n",
    "\n",
    "    n0 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],e2[1]['pos']),'type':'e'})\n",
    "\n",
    "    I1 = (n_id_gen(),{'pos' : avg_pos(e0[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I2 = (n_id_gen(),{'pos' : avg_pos(e1[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I3 = (n_id_gen(),{'pos' : avg_pos(e2[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "    I4 = (n_id_gen(),{'pos' : avg_pos(e3[1]['pos'],n0[1]['pos']),'type':'I','parent':base_node_id})\n",
    "\n",
    "    # add all new edges\n",
    "    new_edges = [\n",
    "        (e0[0],m0[0]),(m0[0],e1[0]),\n",
    "        (e0[0],I1[0]),(m0[0],I1[0]), (m0[0],I2[0]),(e1[0],I2[0]),\n",
    "        (e0[0],m1[0]),(m0[0],n0[0]),(e1[0],m2[0]),\n",
    "        (m1[0],I1[0]),(n0[0],I1[0]), (n0[0],I2[0]),(m2[0],I2[0]),\n",
    "        (m1[0],n0[0]),(n0[0],m2[0]),\n",
    "        (m1[0],I3[0]),(n0[0],I3[0]), (n0[0],I4[0]),(m2[0],I4[0]),\n",
    "        (m1[0],e2[0]),(n0[0],m3[0]),(m2[0],e3[0]),\n",
    "        (e2[0],I3[0]),(m3[0],I3[0]), (m3[0],I4[0]),(e3[0],I4[0]),\n",
    "        (e2[0],m3[0]),(m3[0],e3[0]),\n",
    "    ]\n",
    "    nG.add_nodes_from([e0,e1,e2,e3,m0,m1,m2,n0,m3,I1,I2,I3,I4])\n",
    "    nG.add_edges_from(new_edges)\n",
    "    return nG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def p6_tests():\n",
    "    \n",
    "    def print_res(graph_layers,prod_f, prod,start_layer):\n",
    "        fig1 = plt.figure(1)\n",
    "        graph_layers.display_i_layer(start_layer)\n",
    "        fig1.suptitle(f'base {prod} graph')\n",
    "        plt.show()\n",
    "        print(f'Applying {prod} production on correct graph')\n",
    "        graph_layers.add_new_layer(prod_f())\n",
    "        fig2 = plt.figure(2)\n",
    "        fig2.suptitle(f'production {prod} result')\n",
    "        print('Base layer')\n",
    "        graph_layers.display_i_layer(start_layer)\n",
    "        plt.show()\n",
    "        print('Added layer')\n",
    "        graph_layers.display_i_layer(start_layer+1)\n",
    "        plt.show()\n",
    "        print()\n",
    "    \n",
    "    def prepare_graph(f=None):\n",
    "        graph_layers = Graph_layers()\n",
    "        base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "        first_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "        if f:\n",
    "            G, i_node = f(first_layer_G, base_node[0], graph_layers.get_node_id_gen())\n",
    "            graph_layers.add_new_layer(G)\n",
    "        else:\n",
    "            G, i_node = p1(first_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "            graph_layers.add_new_layer(G)\n",
    "            G = graph_layers.get_layer(1)[0]\n",
    "            G = p2(G, 1, graph_layers.get_node_id_gen())\n",
    "            graph_layers.add_new_layer(G)\n",
    "            graph_layers._layers[2][0].nodes(data=True)\n",
    "        return graph_layers,G,i_node\n",
    "        \n",
    "        \n",
    "    def pX1(G, base_node_id, n_id_gen, side_len=2, max_random_offset = 0):\n",
    "        assert(G.nodes[base_node_id]['type'].lower() == 'e' )\n",
    "        assert(len(G.nodes)==1)\n",
    "        all_new_nodes = []\n",
    "        all_new_edges = []\n",
    "        base_pos = G.nodes[base_node_id]['pos']\n",
    "        x_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "        y_offset = ((np.random.random()-0.5) * max_random_offset * 2)\n",
    "        i_node_x, i_node_y = base_pos[0], base_pos[1]\n",
    "        i_node = (n_id_gen(), {'pos': (i_node_x+x_offset, i_node_y-y_offset), 'type': 'I','parent': -1})\n",
    "        all_new_nodes.append(i_node)\n",
    "\n",
    "        half_side_len = side_len/2\n",
    "        e_nodes = [\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x, i_node_y + half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x + half_side_len, i_node_y),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x, i_node_y - half_side_len),'type': 'e'}),\n",
    "            (n_id_gen(), {'pos': (i_node_x - half_side_len, i_node_y),'type': 'e'})\n",
    "        ]\n",
    "        for i in range(len(e_nodes)):\n",
    "            if i < 4:\n",
    "                all_new_edges.extend([(i_node[0],e_nodes[i][0]), (e_nodes[i][0], e_nodes[i+4][0])])\n",
    "                if i > 0:\n",
    "                    all_new_edges.extend([(e_nodes[i][0], e_nodes[i+3][0])])\n",
    "        \n",
    "        all_new_edges.extend([(e_nodes[0][0], e_nodes[len(e_nodes)-1][0])])\n",
    "        all_new_nodes.extend(e_nodes)\n",
    "        nG = nx.Graph()\n",
    "        nG.add_nodes_from(all_new_nodes)\n",
    "        nG.add_edges_from(all_new_edges)\n",
    "        return nG, i_node\n",
    "    \n",
    "    #test 1\n",
    "    print('p6 simple graph')\n",
    "    graph_layers, G, i_node = prepare_graph(pX1)\n",
    "    print_res(graph_layers,lambda :p6(G, i_node[0], graph_layers.get_node_id_gen()),'p6',1)\n",
    "    \n",
    "    #test 2\n",
    "    print('p6 on subgraph')\n",
    "    graph_layers, G, i_node = prepare_graph()\n",
    "    rm_edge_if_exists(G, 6, 11)\n",
    "    rm_edge_if_exists(G, 6, 10)\n",
    "    rm_edge_if_exists(G, 10, 12)\n",
    "    rm_edge_if_exists(G, 12, 11)\n",
    "    n6 = list(G.nodes(data=True))[0]\n",
    "    n10 = list(G.nodes(data=True))[4]\n",
    "    n11 = list(G.nodes(data=True))[5]\n",
    "    n12 = list(G.nodes(data=True))[6]\n",
    "    n19 = (19, {'pos' : avg_pos(n6[1]['pos'],n11[1]['pos']),'type':'e'})\n",
    "    n20 = (20, {'pos' : avg_pos(n6[1]['pos'],n10[1]['pos']),'type':'e'})\n",
    "    n21 = (21, {'pos' : avg_pos(n10[1]['pos'],n12[1]['pos']),'type':'e'})\n",
    "    n22 = (22, {'pos' : avg_pos(n12[1]['pos'],n11[1]['pos']),'type':'e'})\n",
    "    G.add_nodes_from([n19, n20, n21])\n",
    "    G.add_edges_from([(n6[0], n19[0]), (n19[0], n11[0]), (n20[0], n6[0]), (n10[0], n20[0]),\n",
    "                     (n10[0], n21[0]), (n21[0], n12[0])])\n",
    "    print(\"Trying to use p6 on graph with missing vertex\")\n",
    "    graph_layers.display_i_layer(2)\n",
    "    plt.show()\n",
    "    try:\n",
    "        p6(G, 15, graph_layers.get_node_id_gen())\n",
    "    except CannotExecuteProduction:\n",
    "        print(\"CannotExecuteProduction exception caught\")\n",
    "    G.add_nodes_from([n22])\n",
    "    G.add_edges_from([(n12[0], n22[0])])\n",
    "    print(\"Trying to use p6 on graph with missing edge\")\n",
    "    graph_layers.display_i_layer(2)\n",
    "    plt.show()\n",
    "    try:\n",
    "        p6(G, 15, graph_layers.get_node_id_gen())\n",
    "    except CannotExecuteProduction:\n",
    "        print(\"CannotExecuteProduction exception caught\")\n",
    "    G.add_edges_from([(n22[0], n11[0])])\n",
    "    \n",
    "    print_res(graph_layers,lambda :p6(G, 15, graph_layers.get_node_id_gen()),'p6',2)\n",
    "p6_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#      I1  - e1 - I3\n",
    "#        \\  /   \\ /\n",
    "#         e2    e2\n",
    "#        / \\   / \\\n",
    "#     I2  - e3 - I4\n",
    "#\n",
    "#          |\n",
    "#         \\/\n",
    "#\n",
    "#      I1  - e1 - I3\n",
    "#        \\   |   /\n",
    "#            e2\n",
    "#        /   |   \\\n",
    "#     I2  - e3 - I4\n",
    "\n",
    "def p9(top_layer, lower_layer, base_node_ids, n_ids_gen):\n",
    "    assert_is_true(len(base_node_ids) == 3)\n",
    "    assert_is_true(len(n_ids_gen) == 4)\n",
    "\n",
    "    # Get top graph from layer\n",
    "    top_graphs = list(set([[G for G in top_layer if G.has_node(n_id)][0] for n_id in base_node_ids]))\n",
    "    assert_is_true(len(top_graphs) == 1)\n",
    "    g_top = top_graphs[0]\n",
    "\n",
    "    top_nodes = [(n_id, g_top.nodes[n_id]) for n_id in base_node_ids]\n",
    "    t_nodes_e = [n for n in top_nodes if n[1]['type'].lower() == 'e']\n",
    "    t_nodes_i = [n for n in top_nodes if n[1]['type'].lower() == 'i']\n",
    "    assert_is_true(len(t_nodes_e) == 1)\n",
    "    assert_is_true(len(t_nodes_i) == 2)\n",
    "\n",
    "    t_node_e = t_nodes_e[0]\n",
    "    t_node_i_0 = t_nodes_i[0]\n",
    "    t_node_i_1 = t_nodes_i[1]\n",
    "    assert_is_true(g_top.has_edge(t_node_e[0], t_node_i_0[0]) and g_top.has_edge(t_node_e[0], t_node_i_1[0]))\n",
    "\n",
    "\n",
    "    # Get bottom graph from layer\n",
    "    bot_graph_lists = [[G for G in lower_layer if G.has_node(n_id)] for n_id in n_ids_gen]\n",
    "    for bl in bot_graph_lists:\n",
    "        assert_is_true(len(bl) > 0)\n",
    "    bot_graphs = list(set([b[0] for b in bot_graph_lists]))\n",
    "    assert_is_true(len(bot_graphs) == 1)\n",
    "    g_bot = bot_graphs[0]\n",
    "\n",
    "    bot_nodes = [(n_id, g_bot.nodes[n_id]) for n_id in n_ids_gen]\n",
    "    b_nodes_i = [n for n in bot_nodes if n[1]['type'].lower() == 'i']\n",
    "    assert_is_true(len(b_nodes_i) == 4)\n",
    "\n",
    "\n",
    "    # Get bottom i nodes - for left and right top i\n",
    "    b_nodes_i_l = [n for n in bot_nodes if n[1]['parent'] == t_node_i_0[0]]\n",
    "    b_nodes_i_p = [n for n in bot_nodes if n[1]['parent'] == t_node_i_1[0]]\n",
    "    assert_is_true(len(b_nodes_i_l) == 2)\n",
    "    assert_is_true(len(b_nodes_i_p) == 2)\n",
    "\n",
    "    # Get bottom e nodes\n",
    "    b_nodes_i_l_0_neigh = [(n_id, g_bot.nodes[n_id]) for n_id in g_bot.neighbors(b_nodes_i_l[0][0])\n",
    "                            if g_bot.nodes[n_id]['type'].lower() == 'e']\n",
    "    b_nodes_i_l_1_neigh = [(n_id, g_bot.nodes[n_id]) for n_id in g_bot.neighbors(b_nodes_i_l[1][0])\n",
    "                            if g_bot.nodes[n_id]['type'].lower() == 'e']\n",
    "    b_nodes_i_p_0_neigh = [(n_id, g_bot.nodes[n_id]) for n_id in g_bot.neighbors(b_nodes_i_p[0][0])\n",
    "                            if g_bot.nodes[n_id]['type'].lower() == 'e']\n",
    "    b_nodes_i_p_1_neigh = [(n_id, g_bot.nodes[n_id]) for n_id in g_bot.neighbors(b_nodes_i_p[1][0])\n",
    "                            if g_bot.nodes[n_id]['type'].lower() == 'e']\n",
    "    assert_is_true(len(b_nodes_i_l_0_neigh) > 0)\n",
    "    assert_is_true(len(b_nodes_i_l_1_neigh) > 0)\n",
    "    assert_is_true(len(b_nodes_i_p_0_neigh) > 0)\n",
    "    assert_is_true(len(b_nodes_i_p_1_neigh) > 0)\n",
    "\n",
    "    # Find candidate e nodes\n",
    "    b_nodes_e_l = list({n[0]: n for n in b_nodes_i_l_0_neigh + b_nodes_i_l_1_neigh}.values())\n",
    "    b_nodes_e_p = list({n[0]: n for n in b_nodes_i_p_0_neigh + b_nodes_i_p_1_neigh}.values())\n",
    "\n",
    "    b_nodes_e_lp = [(n0, n1) for n0 in b_nodes_e_l for n1 in b_nodes_e_p\n",
    "                        if n0[0] != n1[0]\n",
    "                        and math.isclose(n0[1]['pos'][0], n1[1]['pos'][0])\n",
    "                        and math.isclose(n0[1]['pos'][1], n1[1]['pos'][1])\n",
    "                        and not g_bot.has_edge(n0[0], n1[0])]\n",
    "    b_nodes_e_o = list({n[0]: n for n in b_nodes_e_l + b_nodes_e_p}.values())\n",
    "\n",
    "    # Find candidate nodes to merge\n",
    "    to_merge = []\n",
    "    for e_t in b_nodes_e_o:\n",
    "        for e_b in b_nodes_e_o:\n",
    "            e_t_id = e_t[0]\n",
    "            e_b_id = e_b[0]\n",
    "            if e_t_id == e_b_id:\n",
    "                continue\n",
    "            for e_m0, e_m1 in b_nodes_e_lp:\n",
    "                e_m0_id = e_m0[0]\n",
    "                e_m1_id = e_m1[0]\n",
    "\n",
    "                if e_t_id == e_m0_id or e_b_id == e_m0_id\\\n",
    "                or e_t_id == e_m1_id or e_b_id == e_m1_id:\n",
    "                    continue\n",
    "\n",
    "                if not g_bot.has_edge(e_t_id, e_m0_id)\\\n",
    "                or not g_bot.has_edge(e_t_id, e_m1_id)\\\n",
    "                or not g_bot.has_edge(e_b_id, e_m0_id)\\\n",
    "                or not g_bot.has_edge(e_b_id, e_m1_id):\n",
    "                    continue\n",
    "\n",
    "                x = (e_t[1]['pos'][0] + e_b[1]['pos'][0]) / 2\n",
    "                y = (e_t[1]['pos'][1] + e_b[1]['pos'][1]) / 2\n",
    "                if not math.isclose(e_m0[1]['pos'][0], x)\\\n",
    "                or not math.isclose(e_m0[1]['pos'][1], y):\n",
    "                    continue\n",
    "\n",
    "                i_l_0_ids = [n_id for n_id, _ in b_nodes_i_l if g_bot.has_edge(n_id, e_t_id) and g_bot.has_edge(n_id, e_m0_id)]\n",
    "                i_l_1_ids = [n_id for n_id, _ in b_nodes_i_l if g_bot.has_edge(n_id, e_b_id) and g_bot.has_edge(n_id, e_m0_id)]\n",
    "                i_p_0_ids = [n_id for n_id, _ in b_nodes_i_p if g_bot.has_edge(n_id, e_t_id) and g_bot.has_edge(n_id, e_m1_id)]\n",
    "                i_p_1_ids = [n_id for n_id, _ in b_nodes_i_p if g_bot.has_edge(n_id, e_b_id) and g_bot.has_edge(n_id, e_m1_id)]\n",
    "\n",
    "                if len(i_l_0_ids) == 0\\\n",
    "                or len(i_l_1_ids) == 0\\\n",
    "                or len(i_p_0_ids) == 0\\\n",
    "                or len(i_p_1_ids) == 0:\n",
    "                    continue\n",
    "                to_merge.append((e_m0_id, e_m1_id))\n",
    "\n",
    "    to_merge = list(set(to_merge))\n",
    "    assert_is_true(len(to_merge) > 0)\n",
    "    u, v = to_merge[0]\n",
    "    new_graph = nx.contracted_nodes(g_bot, u, v)\n",
    "    return new_graph, g_bot\n",
    "\n",
    "def assert_is_true(predicate):\n",
    "    if not predicate:\n",
    "        raise CannotExecuteProduction\n",
    "\n",
    "def apply_p9(parent_layer, child_layer, base_node_ids, n_ids_gen):\n",
    "    new_graph, old_graph = p9(parent_layer, child_layer, base_node_ids, n_ids_gen)\n",
    "    child_layer.remove(old_graph)\n",
    "    child_layer.append(new_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TestNotebookP9(unittest.TestCase):\n",
    "\n",
    "    def create_valid_output_layer(self):\n",
    "        graph_layers = Graph_layers()\n",
    "        id_gen = graph_layers.get_node_id_gen()\n",
    "        l2 = nx.Graph()\n",
    "        l2_edges = []\n",
    "        l2_nodes = []\n",
    "        center_x, center_y, offset, = 2, 2, -1\n",
    "        upper_i_left = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': 2})\n",
    "        lower_i_left = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': 2})\n",
    "        offset = -offset\n",
    "        upper_i_right = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': 3})\n",
    "        lower_i_right = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': 3})\n",
    "\n",
    "        l2_nodes.extend([upper_i_right, upper_i_left, lower_i_left, lower_i_right])\n",
    "\n",
    "        upper_e = (id_gen.get_id(), {'pos': (center_x, center_y + 1.5),'type': 'e'})\n",
    "        mid_e = (id_gen.get_id(), {'pos': (center_x, center_y),'type': 'e'})\n",
    "        lower_e = (id_gen.get_id(), {'pos': (center_x, center_y - 1.5),'type': 'e'})\n",
    "\n",
    "        l2_nodes.extend([upper_e, mid_e, lower_e])\n",
    "        l2_edges.extend([(upper_e[0], mid_e[0]), (lower_e[0], mid_e[0]),\n",
    "                         (lower_e[0], lower_i_left[0]),\n",
    "                         (lower_e[0], lower_i_right[0]),\n",
    "                         (lower_i_left[0], mid_e[0]),\n",
    "                         (lower_i_right[0], mid_e[0]),\n",
    "                         (upper_i_left[0], mid_e[0]),\n",
    "                         (upper_i_right[0], mid_e[0]),\n",
    "                         (upper_i_right[0], upper_e[0]),\n",
    "                         (upper_i_left[0], upper_e[0])])\n",
    "\n",
    "        l2.add_nodes_from(l2_nodes)\n",
    "        l2.add_edges_from(l2_edges)\n",
    "        graph_layers.add_new_layer(l2)\n",
    "#         graph_layers.display_i_layer(1)\n",
    "        return graph_layers.get_layer(1)[0]\n",
    "\n",
    "\n",
    "    def create_leaf_edges(self, parent, id_gen, offset, tiny_offset):\n",
    "        center_x, center_y = 2, 2\n",
    "        l2 = nx.Graph()\n",
    "        l2_edges = []\n",
    "        l2_nodes = []\n",
    "        upper_i_left = (id_gen.get_id(), {'pos': (center_x + offset, center_y + 1),'type': 'I', 'parent': parent[0][0]})\n",
    "        lower_i_left = (id_gen.get_id(), {'pos': (center_x + offset, center_y - 1),'type': 'I', 'parent': parent[0][0]})\n",
    "        upper_i_right = (id_gen.get_id(), {'pos': (center_x - offset, center_y + 1),'type': 'I', 'parent': parent[1][0]})\n",
    "        lower_i_right = (id_gen.get_id(), {'pos': (center_x - offset, center_y - 1),'type': 'I', 'parent': parent[1][0]})\n",
    "        l2_nodes.extend([upper_i_left, lower_i_left, upper_i_right, lower_i_right])\n",
    "\n",
    "        upper_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y + 1.5),'type': 'e'})\n",
    "        mid_e_left = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y),'type': 'e'})\n",
    "        mid_e_right = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y),'type': 'e'})\n",
    "        lower_e = (id_gen.get_id(), {'pos': (center_x + tiny_offset, center_y - 1.5),'type': 'e'})\n",
    "\n",
    "        l2_nodes.extend([upper_e, mid_e_left, mid_e_right, lower_e])\n",
    "        l2_edges.extend([(upper_e[0], mid_e_left[0]), (upper_e[0], mid_e_right[0]),\n",
    "                         (lower_e[0], mid_e_left[0]), (lower_e[0], mid_e_right[0]),\n",
    "                         (upper_i_left[0], upper_e[0]), (upper_i_left[0], mid_e_left[0]),\n",
    "                         (lower_i_left[0], lower_e[0]), (lower_i_left[0], mid_e_left[0]),\n",
    "                         (upper_i_right[0], upper_e[0]), (upper_i_right[0], mid_e_right[0]),\n",
    "                         (lower_i_right[0], lower_e[0]), (lower_i_right[0], mid_e_right[0]),\n",
    "                        ])\n",
    "\n",
    "        l2.add_nodes_from(l2_nodes)\n",
    "        l2.add_edges_from(l2_edges)\n",
    "\n",
    "        return l2, [upper_i_left[0], lower_i_left[0], upper_i_right[0], lower_i_right[0]]\n",
    "\n",
    "    def create_valid_input_net(self):\n",
    "        graph_layers = Graph_layers()\n",
    "        side_len = 2\n",
    "        parent_node_x, parent_node_y = 1, 1\n",
    "        id_gen = graph_layers.get_node_id_gen()\n",
    "        parent_node = (id_gen.get_id(), {'pos': (parent_node_x, parent_node_y), 'type': 'E','parent': -1})\n",
    "\n",
    "        half_side_len = side_len/2\n",
    "        i_nodes = [\n",
    "            (id_gen.get_id(), {'pos': (parent_node_x + half_side_len, parent_node_y - half_side_len),'type': 'I', 'parent': parent_node[0]}),\n",
    "            (id_gen.get_id(), {'pos': (parent_node_x - half_side_len, parent_node_y - half_side_len),'type': 'I', 'parent': parent_node[0]})\n",
    "        ]\n",
    "        l1_edges = []\n",
    "        for i_node in i_nodes:\n",
    "             l1_edges.extend([(i_node[0],parent_node[0])])\n",
    "\n",
    "        l1 = nx.Graph()\n",
    "        l1.add_nodes_from([parent_node])\n",
    "        l1.add_nodes_from(i_nodes)\n",
    "        l1.add_edges_from(l1_edges)\n",
    "        graph_layers.add_new_layer(l1)\n",
    "\n",
    "        center_x, center_y, offset, tiny_offset = 2, 2, -1, -0.05\n",
    "        left_graph, output_ids = self.create_leaf_edges(i_nodes, id_gen, offset, tiny_offset)\n",
    "        graph_layers.add_new_layer(left_graph)\n",
    "        offset = -offset\n",
    "\n",
    "#         graph_layers.display_i_layer(2)\n",
    "\n",
    "        return graph_layers, [parent_node[0], i_nodes[0][0], i_nodes[1][0]], output_ids\n",
    "\n",
    "    def test_p9_correct(self):\n",
    "        initial, intermediate_i_node_ids, output_ids = self.create_valid_input_net()\n",
    "        output = p9(initial.get_layer(1), initial.get_layer(2), intermediate_i_node_ids, output_ids)\n",
    "        assert nx.is_isomorphic(self.create_valid_output_layer(), output[0], node_match=lambda n1,n2: n1['type'] == n2['type'] and n1.get('parent', -2) == n2.get('parent', -2))\n",
    "\n",
    "\n",
    "    def test_p9_remove_random_edge(self):\n",
    "        layers, intermediate_i_node_ids, output_ids = self.create_valid_input_net()\n",
    "        lastLayer = layers.get_layer(2)[0]\n",
    "        edges = list(lastLayer.edges)\n",
    "\n",
    "        # random edge choice\n",
    "        chosen_edge = random.choice(edges)\n",
    "        print(chosen_edge)\n",
    "        lastLayer.remove_edge(chosen_edge[0], chosen_edge[1])\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p9(layers.get_layer(1), [lastLayer], intermediate_i_node_ids, output_ids)\n",
    "\n",
    "\n",
    "    def test_p9_remove_random_node(self):\n",
    "        layers, intermediate_i_node_ids, output_ids = self.create_valid_input_net()\n",
    "        lastLayer = layers.get_layer(2)[0]\n",
    "        nodes = list(lastLayer.nodes)\n",
    "\n",
    "        node_to_remove = random.choice(nodes)\n",
    "        print(node_to_remove)\n",
    "        # random node choice\n",
    "        lastLayer.remove_node(node_to_remove)\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p9(layers.get_layer(1), [lastLayer], intermediate_i_node_ids, output_ids)\n",
    "\n",
    "    def test_p9_incorect_coordinates(self):\n",
    "        layers, intermediate_i_node_ids, output_ids = self.create_valid_input_net()\n",
    "        lastLayer = layers.get_layer(2)[0]\n",
    "        lastLayer.nodes[10]['pos'] = (0, 0)\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p9(layers.get_layer(1), [lastLayer], intermediate_i_node_ids, output_ids)\n",
    "\n",
    "    def test_p9_incorect_label(self):\n",
    "        layers, intermediate_i_node_ids, output_ids = self.create_valid_input_net()\n",
    "        layers.get_layer(2)[0].nodes[5]['type'] = 'e'\n",
    "        lastLayer = layers.get_layer(2)[0]\n",
    "\n",
    "        with self.assertRaises(CannotExecuteProduction):\n",
    "            p9(layers.get_layer(1), [lastLayer], intermediate_i_node_ids, output_ids)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p10(top_layer, base_node_id, n_id_gen):\n",
    "    Gs = { G for G in top_layer if G.has_node(base_node_id) }\n",
    "    assert len(Gs) == 1\n",
    "    G, = Gs\n",
    "\n",
    "    assert G.nodes[base_node_id]['type'].lower() == 'i'\n",
    "    nodes_to_copy, = group_nodes_by_attr(G, list(G.neighbors(base_node_id)), 'type', str.lower).select('e')\n",
    "    assert(len(nodes_to_copy)==4)\n",
    "    \n",
    "    old_to_new = { old_id: n_id_gen() for old_id in nodes_to_copy }\n",
    "    I = n_id_gen()\n",
    "    new_nodes = [\n",
    "        (new_id, {'pos': G.nodes[old_id]['pos'], 'type': 'e'})\n",
    "        for old_id, new_id in old_to_new.items()\n",
    "    ] + [(I, {'pos': G.nodes[base_node_id]['pos'], 'type': 'i', 'parent': base_node_id})]\n",
    "    new_edges = [(new_source_id, old_to_new[old_target_id]) \n",
    "        for old_source_id, new_source_id in old_to_new.items() \n",
    "        for old_target_id in G.neighbors(old_source_id) \n",
    "        if old_target_id in old_to_new\n",
    "    ] + [(I, new_source_id) for old_source_id, new_source_id in old_to_new.items()]\n",
    "\n",
    "    nG = nx.Graph()\n",
    "    nG.add_nodes_from(new_nodes)\n",
    "    nG.add_edges_from(new_edges)\n",
    "    return nG,[I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ta funkcja chyba powinna jednak dzialac w miejscu dla tego grafu bo moga byc 2 albo 1 graf na wejsciu nie wiemy czy\n",
    "## one sa rozdzielne mimo ze w przykladzie produkcji tak jest ale nie mozna wnioskowac czy nie jest to juz zlaczony graf\n",
    "## czy w pelni rozlaczny\n",
    "from networkx.algorithms.operators.binary import compose \n",
    "\n",
    "def flatten(t):\n",
    "    return  [item for sublist in t for item in sublist]\n",
    "\n",
    "def get_graph_e_nodes_with_pos(G):\n",
    "    return [(key, G.nodes[key]['pos']) for (key, value) in nx.get_node_attributes(G, 'type').items() if value == 'e']\n",
    "\n",
    "def exist_edge(graphs, e1, e2):\n",
    "    return sum([int(g.has_edge(e1, e2))for g in graphs]) > 0\n",
    "\n",
    "def reasing(graph, e1, e2):\n",
    "    edges = graph.edges(e1)\n",
    "    to_remove = []\n",
    "    to_add = []\n",
    "    for e in edges:\n",
    "        _, to = e\n",
    "        to_add.append((e2, to))\n",
    "        to_remove.append(e)            \n",
    "    for e in to_remove:\n",
    "        graph.remove_edge(e[0], e[1])  \n",
    "    for e in to_add:\n",
    "        graph.add_edge(e[0], e[1])\n",
    "\n",
    "def p11(top_layer, lower_layer, base_node_ids, n_id_gen):\n",
    "    assert len(base_node_ids) == 3\n",
    "\n",
    "    # step 1) select lower graph \n",
    "    lower_graphs = { G for n_id in base_node_ids for G in lower_layer if G.has_node(n_id) }    \n",
    "    top_I_Nodes = [get_parent_of_nodes(g, base_node_ids) for g in lower_graphs]\n",
    "    assert len(top_I_Nodes) == 2\n",
    "    \n",
    "    # znajdz nody i\n",
    "    i1 = base_node_ids[0]\n",
    "    i1_parent = flatten([get_parent_of_nodes(g, [i1]) for g in lower_graphs])\n",
    "    i2 = base_node_ids[1]\n",
    "    i2_parent = flatten([get_parent_of_nodes(g, [i2]) for g in lower_graphs])\n",
    "    i3 = base_node_ids[2]\n",
    "    i3_parent = flatten([get_parent_of_nodes(g, [i3]) for g in lower_graphs])\n",
    "\n",
    "    # sprawdz po ktorej stronie mamy dwa nody i\n",
    "    i_lone, i_double_1, i_double_2 = None, None, None\n",
    "    if i1_parent == i2_parent:\n",
    "        i_lone, i_double_1, i_double_2 = i3, i1, i2\n",
    "    if i1_parent == i3_parent:\n",
    "        i_lone, i_double_1, i_double_2 = i2, i1, i3\n",
    "    if i3_parent == i2_parent:\n",
    "        i_lone, i_double_1, i_double_2 = i1, i3, i2\n",
    "    \n",
    "    e_nodes = flatten([get_graph_e_nodes_with_pos(g) for g in lower_graphs])\n",
    "    pairs = []\n",
    "    \n",
    "    # znajdz pary nodow o tych samych wspolrzednych\n",
    "    for e1 in e_nodes:\n",
    "        for e2 in e_nodes:\n",
    "            if(e1[0] < e2[0] and math.isclose(e1[1][0], e2[1][0]) and math.isclose(e1[1][1], e2[1][1])):\n",
    "                pairs.append((e1[0], e2[0]))\n",
    "    \n",
    "    assert len(pairs) == 2\n",
    "    found_nodes = flatten([list(p) for p in pairs])\n",
    "    #znajdz te 2 nody ktore byly dla pojedynczego i (bedziemy odpinac stad krawedzie i usuwac te nody)\n",
    "    nodes_for_lone_i = [f for f in found_nodes if exist_edge(lower_graphs, f, i_lone)]\n",
    "    \n",
    "    lower = list(lower_graphs)\n",
    "    \n",
    "    # zrob kompozycje grafow jezeli trzeba\n",
    "    composed = None\n",
    "    if (len(lower) == 1):\n",
    "        composed = lower[0]\n",
    "    else: \n",
    "        g1 = lower[0]\n",
    "        g2 = lower[1]\n",
    "        g1.add_nodes_from(g2.nodes(data=True))\n",
    "        g1.add_edges_from(g2.edges(data=True))\n",
    "        lower_layer.remove(g2)\n",
    "        composed = g1\n",
    "    composed.remove_edge(nodes_for_lone_i[0], nodes_for_lone_i[1])\n",
    "    # przepinanie nodow\n",
    "    for n in nodes_for_lone_i:\n",
    "        reasing_to = [ a if n == b else b for a, b in pairs if a == n or b == n][0]\n",
    "        reasing(composed, n, reasing_to)\n",
    "        composed.remove_node(n)\n",
    "    return composed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p12(top_layer, lower_layer, base_node_ids, n_id_gen):\n",
    "    assert len(base_node_ids) == 3\n",
    "\n",
    "    lower_graphs = { G for n_id in base_node_ids for G in lower_layer if G.has_node(n_id) }    \n",
    "    top_I_Nodes = flatten([get_parent_of_nodes(g, base_node_ids) for g in lower_graphs])\n",
    "    assert len(top_I_Nodes) == 2\n",
    "    assert len(lower_graphs) == 1\n",
    "    lower_graph = list(lower_graphs)[0]\n",
    "    \n",
    "    i1 = base_node_ids[0]\n",
    "    i1_parent = flatten([get_parent_of_nodes(g, [i1]) for g in lower_graphs])\n",
    "    i2 = base_node_ids[1]\n",
    "    i2_parent = flatten([get_parent_of_nodes(g, [i2]) for g in lower_graphs])\n",
    "    i3 = base_node_ids[2]\n",
    "    i3_parent = flatten([get_parent_of_nodes(g, [i3]) for g in lower_graphs])\n",
    "\n",
    "    i_lone, i_double_1, i_double_2 = None, None, None\n",
    "    if i1_parent == i2_parent:\n",
    "        i_lone, i_double_1, i_double_2 = i3, i1, i2\n",
    "    if i1_parent == i3_parent:\n",
    "        i_lone, i_double_1, i_double_2 = i2, i1, i3\n",
    "    if i3_parent == i2_parent:\n",
    "        i_lone, i_double_1, i_double_2 = i1, i3, i2\n",
    "    \n",
    "    e_nodes = flatten([get_graph_e_nodes_with_pos(g) for g in lower_graphs])\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    # powinna byc tylko jedna para nodow o tych samych wspolrzednych ale roznych id \n",
    "    for e1 in e_nodes:\n",
    "        for e2 in e_nodes:\n",
    "            if(e1[0] < e2[0] and math.isclose(e1[1][0], e2[1][0]) and math.isclose(e1[1][1], e2[1][1])):\n",
    "                pairs.append((e1[0], e2[0]))\n",
    "    \n",
    "    assert len(pairs) == 1\n",
    "    \n",
    "    # to jest ten smieszny zlaczony wierzcholek\n",
    "    shared_e = None\n",
    "    for e in e_nodes:\n",
    "        print(e)\n",
    "        if lower_graph.has_edge(e[0], i_lone) and (lower_graph.has_edge(e[0], i_double_2) or lower_graph.has_edge(e[0], i_double_1)):\n",
    "            shared_e = e[0]\n",
    "            \n",
    "    found_nodes = flatten([list(p) for p in pairs])\n",
    "    nodes_for_lone_i = [f for f in found_nodes if exist_edge(lower_graphs, f, i_lone)] + [shared_e]\n",
    "    print(nodes_for_lone_i)\n",
    "    # dla strony z ktorej mamy 1 node i usuwamy krawdz pomiedzy sharowanym nodem a tym drugim\n",
    "    lower_graph.remove_edge(nodes_for_lone_i[0], nodes_for_lone_i[1])\n",
    "    \n",
    "    pair = pairs[0]\n",
    "    to_node = pair[0] if pair[0] not in set(nodes_for_lone_i) else pair[1]\n",
    "    from_node = pair[0] if pair[0] in set(nodes_for_lone_i) else pair[1]\n",
    "    # przepinamy wszystko z noda po prawej na tego po lewej\n",
    "    reasing(lower_graph, from_node, to_node)\n",
    "    lower_graph.remove_node(from_node)\n",
    "    return lower_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_layers = Graph_layers()\n",
    "#graph_layers.display_i_layer(0)\n",
    "\n",
    "base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "#indexing from 0 \n",
    "first_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "\n",
    "#apply p1 production\n",
    "G, i_node = p1(first_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "graph_layers.add_new_layer(G)\n",
    "\n",
    "#graph_layers.display_i_layer(1)\n",
    "\n",
    "#apply p2 production\n",
    "G = graph_layers.get_layer(1)[0]\n",
    "nG = p2(G, 1, graph_layers.get_node_id_gen())\n",
    "graph_layers.add_new_layer(nG)\n",
    "graph_layers._layers[2][0].nodes(data=True)\n",
    "#graph_layers.display_i_layer(2)\n",
    "\n",
    "#apply p2 production 4 times\n",
    "G = graph_layers.get_layer(2)[0]\n",
    "graph_layers.add_new_layer( p2(G, 17, graph_layers.get_node_id_gen()))\n",
    "graph_layers.add_to_last_layer(p2(G, 18, graph_layers.get_node_id_gen()))\n",
    "#graph_layers.display_i_layer(3)\n",
    "\n",
    "#apply p2 production\n",
    "G = graph_layers.get_layer(2)\n",
    "a,b = p10(G, 15, graph_layers.get_node_id_gen())\n",
    "graph_layers.add_to_last_layer(a)\n",
    "#graph_layers.display_i_layer(3)\n",
    "\n",
    "#apply p2 production\n",
    "G = graph_layers.get_layer(2)\n",
    "a,b = p10(G, 16, graph_layers.get_node_id_gen())\n",
    "graph_layers.add_to_last_layer(a)\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt = graph_layers.get_layer(2)\n",
    "Gb = graph_layers.get_layer(3)\n",
    "p11(Gt, Gb, [41,42,54], graph_layers.get_node_id_gen())\n",
    "\n",
    "Gt = graph_layers.get_layer(2)\n",
    "Gb = graph_layers.get_layer(3)\n",
    "p11(Gt, Gb, [49,28,29], graph_layers.get_node_id_gen())\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_layers = Graph_layers()\n",
    "#graph_layers.display_i_layer(0)\n",
    "\n",
    "base_node = list(graph_layers.get_layer(0)[0].nodes(data=True))[0]\n",
    "#indexing from 0 \n",
    "first_layer_G = graph_layers.get_layer(0)[0].copy()\n",
    "\n",
    "#apply p1 production\n",
    "G, i_node = p1(first_layer_G, base_node[0], graph_layers.get_node_id_gen()) \n",
    "graph_layers.add_new_layer(G)\n",
    "\n",
    "#graph_layers.display_i_layer(1)\n",
    "\n",
    "#apply p2 production\n",
    "G = graph_layers.get_layer(1)[0]\n",
    "nG = p2(G, 1, graph_layers.get_node_id_gen())\n",
    "graph_layers.add_new_layer(nG)\n",
    "graph_layers._layers[2][0].nodes(data=True)\n",
    "#graph_layers.display_i_layer(2)\n",
    "\n",
    "#apply p2 production 4 times\n",
    "G = graph_layers.get_layer(2)[0]\n",
    "graph_layers.add_new_layer( p2(G, 17, graph_layers.get_node_id_gen()))\n",
    "#graph_layers.display_i_layer(3)\n",
    "\n",
    "\n",
    "#apply p2 production\n",
    "G = graph_layers.get_layer(2)\n",
    "a,b = p10(G, 15, graph_layers.get_node_id_gen())\n",
    "graph_layers.add_to_last_layer(a)\n",
    "#graph_layers.display_i_layer(3)\n",
    "G = graph_layers.get_layer(3)\n",
    "H = compose(G[0], G[1])\n",
    "G.remove(G[1])\n",
    "G.remove(G[0])\n",
    "graph_layers.add_to_last_layer(H)\n",
    "reasing(H, 35 , 20)\n",
    "H.remove_node(35)\n",
    "graph_layers.display_i_layer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt = graph_layers.get_layer(2)\n",
    "Gb = graph_layers.get_layer(3)\n",
    "p12(Gt, Gb, [36,28,29], graph_layers.get_node_id_gen())\n",
    "graph_layers.display_i_layer(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
